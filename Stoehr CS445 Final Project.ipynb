{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe223a9",
   "metadata": {},
   "source": [
    "# Classifying Codon Frequencies using a Neural Network Classifier\n",
    "\n",
    "##### Shannon Stoehr CS 445 Final Project\n",
    "\n",
    "The data set used for this project is courtesy of the Machine Learning Repository of UC Irvine.\n",
    "\n",
    "During my work I found typos for the Salmonella enterica subsp. enterica serovar 4,12;I and the Non-A, non-B hepatitis virus entries. They have been updated manually using the codon information from https://www.kazusa.or.jp/codon/cgi-bin/showcodon.cgi?species=353569 and https://www.kazusa.or.jp/codon/cgi-bin/showcodon.cgi?species=12440. I have included a copy of the data I used with this assignment.\n",
    "\n",
    "Source: Bohdan Khomtchouk, Ph.D. University of Chicago, Department of Medicine, Section of Computational Biomedicine and Biomedical Data Science. (https://archive.ics.uci.edu/ml/datasets/Codon+usage). Email: bohdan@uchicago.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be73ea6",
   "metadata": {},
   "source": [
    "## What are Codons?\n",
    "\n",
    "The Central Dogma of genetics is that DNA is transcribed into RNA which is then translated into protein. The nucleotide \"alphabet\" consists of adenine (A), cytosine (C), guanine (G), and thymine (T, DNA only) or uracil (U, RNA only). A codon is a nucleotide triplet (ex. AUG) that is eventually translated into an amino acid (ex. AUG ðŸ¡² Methionine) or a release factor (ex. UAA/UAG/UGA ðŸ¡² stop codons, halting translation). There are 64 total codon possibilities (4^3) as shown below. It's important to know that some codons will code for the same amino acid (eg. GU_ all code for Valine). This phenomenon is known as redundancy: it's important because it can help minimize the negative effects that incorrectly placed nucleotides can have on protein synthesis (https://www.nature.com/scitable/topicpage/the-information-in-dna-determines-cellular-function-6523228/).\n",
    "\n",
    "![A codon chart showing all 64 possibilities.](https://cdn.kastatic.org/ka-perseus-images/f5de6355003ee322782b26404ef0733a1d1a61b0.png)\n",
    "Source: Khan Academy (https://www.khanacademy.org/science/ap-biology/gene-expression-and-regulation/translation/a/the-genetic-code-discovery-and-properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea655f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kingdom</th>\n",
       "      <th>DNAtype</th>\n",
       "      <th>SpeciesID</th>\n",
       "      <th>Ncodons</th>\n",
       "      <th>SpeciesName</th>\n",
       "      <th>UUU</th>\n",
       "      <th>UUC</th>\n",
       "      <th>UUA</th>\n",
       "      <th>UUG</th>\n",
       "      <th>CUU</th>\n",
       "      <th>...</th>\n",
       "      <th>CGG</th>\n",
       "      <th>AGA</th>\n",
       "      <th>AGG</th>\n",
       "      <th>GAU</th>\n",
       "      <th>GAC</th>\n",
       "      <th>GAA</th>\n",
       "      <th>GAG</th>\n",
       "      <th>UAA</th>\n",
       "      <th>UAG</th>\n",
       "      <th>UGA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vrl</td>\n",
       "      <td>0</td>\n",
       "      <td>100217</td>\n",
       "      <td>1995</td>\n",
       "      <td>Epizootic haematopoietic necrosis virus</td>\n",
       "      <td>0.01654</td>\n",
       "      <td>0.01203</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>0.00351</td>\n",
       "      <td>0.01203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00451</td>\n",
       "      <td>0.01303</td>\n",
       "      <td>0.03559</td>\n",
       "      <td>0.01003</td>\n",
       "      <td>0.04612</td>\n",
       "      <td>0.01203</td>\n",
       "      <td>0.04361</td>\n",
       "      <td>0.00251</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vrl</td>\n",
       "      <td>0</td>\n",
       "      <td>100220</td>\n",
       "      <td>1474</td>\n",
       "      <td>Bohle iridovirus</td>\n",
       "      <td>0.02714</td>\n",
       "      <td>0.01357</td>\n",
       "      <td>0.00068</td>\n",
       "      <td>0.00678</td>\n",
       "      <td>0.00407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00136</td>\n",
       "      <td>0.01696</td>\n",
       "      <td>0.03596</td>\n",
       "      <td>0.01221</td>\n",
       "      <td>0.04545</td>\n",
       "      <td>0.01560</td>\n",
       "      <td>0.04410</td>\n",
       "      <td>0.00271</td>\n",
       "      <td>0.00068</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vrl</td>\n",
       "      <td>0</td>\n",
       "      <td>100755</td>\n",
       "      <td>4862</td>\n",
       "      <td>Sweet potato leaf curl virus</td>\n",
       "      <td>0.01974</td>\n",
       "      <td>0.02180</td>\n",
       "      <td>0.01357</td>\n",
       "      <td>0.01543</td>\n",
       "      <td>0.00782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00596</td>\n",
       "      <td>0.01974</td>\n",
       "      <td>0.02489</td>\n",
       "      <td>0.03126</td>\n",
       "      <td>0.02036</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.02468</td>\n",
       "      <td>0.00391</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vrl</td>\n",
       "      <td>0</td>\n",
       "      <td>100880</td>\n",
       "      <td>1915</td>\n",
       "      <td>Northern cereal mosaic virus</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>0.02245</td>\n",
       "      <td>0.01619</td>\n",
       "      <td>0.00992</td>\n",
       "      <td>0.01567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00366</td>\n",
       "      <td>0.01410</td>\n",
       "      <td>0.01671</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.01932</td>\n",
       "      <td>0.03029</td>\n",
       "      <td>0.03446</td>\n",
       "      <td>0.00261</td>\n",
       "      <td>0.00157</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vrl</td>\n",
       "      <td>0</td>\n",
       "      <td>100887</td>\n",
       "      <td>22831</td>\n",
       "      <td>Soil-borne cereal mosaic virus</td>\n",
       "      <td>0.02816</td>\n",
       "      <td>0.01371</td>\n",
       "      <td>0.00767</td>\n",
       "      <td>0.03679</td>\n",
       "      <td>0.01380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00604</td>\n",
       "      <td>0.01494</td>\n",
       "      <td>0.01734</td>\n",
       "      <td>0.04148</td>\n",
       "      <td>0.02483</td>\n",
       "      <td>0.03359</td>\n",
       "      <td>0.03679</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13023</th>\n",
       "      <td>pri</td>\n",
       "      <td>0</td>\n",
       "      <td>9601</td>\n",
       "      <td>1097</td>\n",
       "      <td>Pongo pygmaeus abelii</td>\n",
       "      <td>0.02552</td>\n",
       "      <td>0.03555</td>\n",
       "      <td>0.00547</td>\n",
       "      <td>0.01367</td>\n",
       "      <td>0.01276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00820</td>\n",
       "      <td>0.01367</td>\n",
       "      <td>0.01094</td>\n",
       "      <td>0.01367</td>\n",
       "      <td>0.02279</td>\n",
       "      <td>0.02005</td>\n",
       "      <td>0.04102</td>\n",
       "      <td>0.00091</td>\n",
       "      <td>0.00091</td>\n",
       "      <td>0.00638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13024</th>\n",
       "      <td>pri</td>\n",
       "      <td>1</td>\n",
       "      <td>9601</td>\n",
       "      <td>2067</td>\n",
       "      <td>mitochondrion Pongo pygmaeus abelii</td>\n",
       "      <td>0.01258</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.01984</td>\n",
       "      <td>0.00629</td>\n",
       "      <td>0.01451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00145</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00048</td>\n",
       "      <td>0.00194</td>\n",
       "      <td>0.01306</td>\n",
       "      <td>0.01838</td>\n",
       "      <td>0.00677</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00097</td>\n",
       "      <td>0.01887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13025</th>\n",
       "      <td>pri</td>\n",
       "      <td>1</td>\n",
       "      <td>9602</td>\n",
       "      <td>1686</td>\n",
       "      <td>mitochondrion Pongo pygmaeus pygmaeus</td>\n",
       "      <td>0.01423</td>\n",
       "      <td>0.03321</td>\n",
       "      <td>0.01661</td>\n",
       "      <td>0.00356</td>\n",
       "      <td>0.01127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00178</td>\n",
       "      <td>0.01661</td>\n",
       "      <td>0.02788</td>\n",
       "      <td>0.00297</td>\n",
       "      <td>0.00356</td>\n",
       "      <td>0.00119</td>\n",
       "      <td>0.02017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13026</th>\n",
       "      <td>pri</td>\n",
       "      <td>0</td>\n",
       "      <td>9606</td>\n",
       "      <td>40662582</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>0.01757</td>\n",
       "      <td>0.02028</td>\n",
       "      <td>0.00767</td>\n",
       "      <td>0.01293</td>\n",
       "      <td>0.01319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01142</td>\n",
       "      <td>0.01217</td>\n",
       "      <td>0.01196</td>\n",
       "      <td>0.02178</td>\n",
       "      <td>0.02510</td>\n",
       "      <td>0.02896</td>\n",
       "      <td>0.03959</td>\n",
       "      <td>0.00099</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>0.00156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13027</th>\n",
       "      <td>pri</td>\n",
       "      <td>1</td>\n",
       "      <td>9606</td>\n",
       "      <td>8998998</td>\n",
       "      <td>mitochondrion Homo sapiens</td>\n",
       "      <td>0.01778</td>\n",
       "      <td>0.03724</td>\n",
       "      <td>0.01732</td>\n",
       "      <td>0.00600</td>\n",
       "      <td>0.01689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00083</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.00451</td>\n",
       "      <td>0.01402</td>\n",
       "      <td>0.01651</td>\n",
       "      <td>0.00783</td>\n",
       "      <td>0.00156</td>\n",
       "      <td>0.00114</td>\n",
       "      <td>0.02161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13028 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Kingdom  DNAtype  SpeciesID   Ncodons  \\\n",
       "0         vrl        0     100217      1995   \n",
       "1         vrl        0     100220      1474   \n",
       "2         vrl        0     100755      4862   \n",
       "3         vrl        0     100880      1915   \n",
       "4         vrl        0     100887     22831   \n",
       "...       ...      ...        ...       ...   \n",
       "13023     pri        0       9601      1097   \n",
       "13024     pri        1       9601      2067   \n",
       "13025     pri        1       9602      1686   \n",
       "13026     pri        0       9606  40662582   \n",
       "13027     pri        1       9606   8998998   \n",
       "\n",
       "                                   SpeciesName      UUU      UUC      UUA  \\\n",
       "0      Epizootic haematopoietic necrosis virus  0.01654  0.01203  0.00050   \n",
       "1                             Bohle iridovirus  0.02714  0.01357  0.00068   \n",
       "2                 Sweet potato leaf curl virus  0.01974  0.02180  0.01357   \n",
       "3                 Northern cereal mosaic virus  0.01775  0.02245  0.01619   \n",
       "4               Soil-borne cereal mosaic virus  0.02816  0.01371  0.00767   \n",
       "...                                        ...      ...      ...      ...   \n",
       "13023                    Pongo pygmaeus abelii  0.02552  0.03555  0.00547   \n",
       "13024      mitochondrion Pongo pygmaeus abelii  0.01258  0.03193  0.01984   \n",
       "13025    mitochondrion Pongo pygmaeus pygmaeus  0.01423  0.03321  0.01661   \n",
       "13026                             Homo sapiens  0.01757  0.02028  0.00767   \n",
       "13027               mitochondrion Homo sapiens  0.01778  0.03724  0.01732   \n",
       "\n",
       "           UUG      CUU  ...      CGG      AGA      AGG      GAU      GAC  \\\n",
       "0      0.00351  0.01203  ...  0.00451  0.01303  0.03559  0.01003  0.04612   \n",
       "1      0.00678  0.00407  ...  0.00136  0.01696  0.03596  0.01221  0.04545   \n",
       "2      0.01543  0.00782  ...  0.00596  0.01974  0.02489  0.03126  0.02036   \n",
       "3      0.00992  0.01567  ...  0.00366  0.01410  0.01671  0.03760  0.01932   \n",
       "4      0.03679  0.01380  ...  0.00604  0.01494  0.01734  0.04148  0.02483   \n",
       "...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "13023  0.01367  0.01276  ...  0.00820  0.01367  0.01094  0.01367  0.02279   \n",
       "13024  0.00629  0.01451  ...  0.00145  0.00000  0.00048  0.00194  0.01306   \n",
       "13025  0.00356  0.01127  ...  0.00000  0.00000  0.00000  0.00178  0.01661   \n",
       "13026  0.01293  0.01319  ...  0.01142  0.01217  0.01196  0.02178  0.02510   \n",
       "13027  0.00600  0.01689  ...  0.00083  0.00041  0.00041  0.00451  0.01402   \n",
       "\n",
       "           GAA      GAG      UAA      UAG      UGA  \n",
       "0      0.01203  0.04361  0.00251  0.00050  0.00000  \n",
       "1      0.01560  0.04410  0.00271  0.00068  0.00000  \n",
       "2      0.02242  0.02468  0.00391  0.00000  0.00144  \n",
       "3      0.03029  0.03446  0.00261  0.00157  0.00000  \n",
       "4      0.03359  0.03679  0.00000  0.00044  0.00131  \n",
       "...        ...      ...      ...      ...      ...  \n",
       "13023  0.02005  0.04102  0.00091  0.00091  0.00638  \n",
       "13024  0.01838  0.00677  0.00242  0.00097  0.01887  \n",
       "13025  0.02788  0.00297  0.00356  0.00119  0.02017  \n",
       "13026  0.02896  0.03959  0.00099  0.00079  0.00156  \n",
       "13027  0.01651  0.00783  0.00156  0.00114  0.02161  \n",
       "\n",
       "[13028 rows x 69 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the data\n",
    "import pandas\n",
    "data = pandas.read_csv('codon_usageCOPY.csv', low_memory=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19c3d8",
   "metadata": {},
   "source": [
    "## Attribute Information\n",
    "\n",
    "##### From https://archive.ics.uci.edu/ml/datasets/Codon+usage\n",
    "\n",
    "### **Column 1: Kingdom**\n",
    "\n",
    "The 'Kingdom' is a 3-letter code corresponding to 'xxx' in the CUTG database name: 'arc'(archaea), 'bct'(bacteria), 'phg'(bacteriophage), 'plm' (plasmid), 'pln' (plant), 'inv' (invertebrate), 'vrt' (vertebrate), 'mam' (mammal), 'rod' (rodent), 'pri' (primate), and 'vrl'(virus) sequence entries. Note that the CUTG database does not contain 'arc' and 'plm' (these have been manually curated ourselves).\n",
    "\n",
    "* 'arc'(archaea)\n",
    "* 'bct'(bacteria)\n",
    "* 'phg'(bacteriophage)\n",
    "* 'plm' (plasmid)\n",
    "* 'pln' (plant)\n",
    "* 'inv' (invertebrate)\n",
    "* 'vrt' (vertebrate)\n",
    "* 'mam' (mammal)\n",
    "* 'rod' (rodent)\n",
    "* 'pri' (primate)\n",
    "* 'vrl' (virus)\n",
    "\n",
    "**Column 2: DNAtype**\n",
    "\n",
    "The 'DNAtype' is denoted as an integer for the genomic composition in the species: 0-genomic, 1-mitochondrial, 2-chloroplast, 3-cyanelle, 4-plastid, 5-nucleomorph, 6-secondary_endosymbiont, 7-chromoplast, 8-leucoplast, 9-NA, 10-proplastid, 11-apicoplast, and 12-kinetoplast.\n",
    "\n",
    "* 0 (genomic)\n",
    "* 1 (mitochondrial)\n",
    "* 2 (chloroplast)\n",
    "* 3 (cyanelle)\n",
    "* 4 (plastid)\n",
    "* 5 (nucleomorph)\n",
    "* 6 (secondary_endosymbiont)\n",
    "* 7 (chromoplast)\n",
    "* 8 (leucoplast)\n",
    "* 9 (NA)\n",
    "* 10 (proplastid)\n",
    "* 11 (apicoplast)\n",
    "* 12 (kinetoplast)\n",
    "\n",
    "**Column 3: SpeciesID**\n",
    "\n",
    "The species identifier ('SpeciesID') is an integer, which uniquely indicates the entries of an organism. It is an accession identifier for each different species in the original CUTG database, followed by the first item listed in each genome. *This will not be used for classification.*\n",
    "\n",
    "**Column 4: Ncodons**\n",
    "\n",
    "The number of codons ('Ncodons') is the algebraic sum of the numbers listed for the different codons in an entry of CUTG. Codon frequencies are normalized to the total codon count, hence the number of occurrences divided by 'Ncodons' is the codon frequencies listed in the data file. *This will not be used for classification.*\n",
    "\n",
    "**Column 5: SpeciesName**\n",
    "\n",
    "The species' name ('SpeciesName') is represented in strings purged of 'comma' (which are now replaced by 'space'). This is a descriptive label of the name of the species for data interpretations. *This will not be used for classification.*\n",
    "\n",
    "**Columns 6-69: codon**\n",
    "\n",
    "Lastly, the codon frequencies ('codon') including 'UUU', 'UUA', 'UUG', 'CUU', etc., are recorded as floats (with decimals in 5 digits).\n",
    "\n",
    "There are a total of 13028 samples, each with 69 attributes. These will be the input values for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e595ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from A4: Classification of Hand-Drawn Digits\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62856abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting optimizers.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile optimizers.py\n",
    "import numpy as np\n",
    "\n",
    "######################################################################\n",
    "## class Optimizers()\n",
    "######################################################################\n",
    "\n",
    "class Optimizers():\n",
    "\n",
    "    def __init__(self, all_weights):\n",
    "        '''all_weights is a vector of all of a neural networks weights concatenated into a one-dimensional vector'''\n",
    "        \n",
    "        self.all_weights = all_weights\n",
    "\n",
    "        # The following initializations are only used by adam.\n",
    "        # Only initializing m, v, beta1t and beta2t here allows multiple calls to adam to handle training\n",
    "        # with multiple subsets (batches) of training data.\n",
    "        self.mt = np.zeros_like(all_weights)\n",
    "        self.vt = np.zeros_like(all_weights)\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.beta1t = 1\n",
    "        self.beta2t = 1\n",
    "\n",
    "        \n",
    "    def sgd(self, error_f, gradient_f, fargs=[], n_epochs=100, learning_rate=0.001, verbose=True, error_convert_f=None):\n",
    "        \n",
    "        # error_f: function that requires X and T as arguments (given in fargs) and returns mean squared error.\n",
    "        # gradient_f: function that requires X and T as arguments (in fargs) and returns gradient of mean squared error with respect to each weight.\n",
    "        # error_convert_f: function that converts the standardized error from error_f to original T units.\n",
    "\n",
    "        error_trace = []\n",
    "        epochs_per_print = n_epochs // 10\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            error = error_f(*fargs)\n",
    "            grad = gradient_f(*fargs)\n",
    "\n",
    "            # Update all weights using -= to modify their values in-place.\n",
    "            self.all_weights -= learning_rate * grad\n",
    "\n",
    "            if error_convert_f:\n",
    "                error = error_convert_f(error)\n",
    "            error_trace.append(error)\n",
    "\n",
    "            if verbose and ((epoch + 1) % max(1, epochs_per_print) == 0):\n",
    "                print(f'sgd: Epoch {epoch+1:d} Error={error:.5f}')\n",
    "\n",
    "        return error_trace\n",
    "\n",
    "    def adam(self, error_f, gradient_f, fargs=[], n_epochs=100, learning_rate=0.001, verbose=True, error_convert_f=None):\n",
    "        # error_f: function that requires X and T as arguments (given in fargs) and returns mean squared error.\n",
    "        # gradient_f: function that requires X and T as arguments (in fargs) and returns gradient of mean squared error with respect to each weight.\n",
    "        # error_convert_f: function that converts the standardized error from error_f to original T units.\n",
    "\n",
    "        alpha = learning_rate  # learning rate called alpha in original paper on adam\n",
    "        epsilon = 1e-8\n",
    "        error_trace = []\n",
    "        epochs_per_print = n_epochs // 10\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            error = error_f(*fargs)\n",
    "            grad = gradient_f(*fargs)\n",
    "\n",
    "            self.mt[:] = self.beta1 * self.mt + (1 - self.beta1) * grad\n",
    "            self.vt[:] = self.beta2 * self.vt + (1 - self.beta2) * grad * grad\n",
    "            self.beta1t *= self.beta1\n",
    "            self.beta2t *= self.beta2\n",
    "\n",
    "            m_hat = self.mt / (1 - self.beta1t)\n",
    "            v_hat = self.vt / (1 - self.beta2t)\n",
    "\n",
    "            # Update all weights using -= to modify their values in-place.\n",
    "            self.all_weights -= alpha * m_hat / (np.sqrt(v_hat) + epsilon)\n",
    "    \n",
    "            if error_convert_f:\n",
    "                error = error_convert_f(error)\n",
    "            error_trace.append(error)\n",
    "\n",
    "            if verbose and ((epoch + 1) % max(1, epochs_per_print) == 0):\n",
    "                print(f'Adam: Epoch {epoch+1:d} Error={error:.5f}')\n",
    "\n",
    "        return error_trace\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.ion()\n",
    "\n",
    "    def parabola(wmin):\n",
    "        return ((w - wmin) ** 2)[0]\n",
    "\n",
    "    def parabola_gradient(wmin):\n",
    "        return 2 * (w - wmin)\n",
    "\n",
    "    w = np.array([0.0])\n",
    "    optimizer = Optimizers(w)\n",
    "\n",
    "    wmin = 5\n",
    "    optimizer.sgd(parabola, parabola_gradient, [wmin],\n",
    "                  n_epochs=500, learning_rate=0.1)\n",
    "\n",
    "    print(f'sgd: Minimum of parabola is at {wmin}. Value found is {w}')\n",
    "\n",
    "    w = np.array([0.0])\n",
    "    optimizer = Optimizers(w)\n",
    "    optimizer.adam(parabola, parabola_gradient, [wmin],\n",
    "                   n_epochs=500, learning_rate=0.1)\n",
    "    \n",
    "    print(f'adam: Minimum of parabola is at {wmin}. Value found is {w}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f38d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from A4: Classification of Hand-Drawn Digits\n",
    "import numpy as np\n",
    "import optimizers\n",
    "import sys  # for sys.float_info.epsilon\n",
    "\n",
    "######################################################################\n",
    "## class NeuralNetwork()\n",
    "######################################################################\n",
    "\n",
    "class NeuralNetwork():\n",
    "\n",
    "\n",
    "    def __init__(self, n_inputs, n_hiddens_per_layer, n_outputs, activation_function='tanh'):\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "        # Set self.n_hiddens_per_layer to [] if argument is 0, [], or [0]\n",
    "        if n_hiddens_per_layer == 0 or n_hiddens_per_layer == [] or n_hiddens_per_layer == [0]:\n",
    "            self.n_hiddens_per_layer = []\n",
    "        else:\n",
    "            self.n_hiddens_per_layer = n_hiddens_per_layer\n",
    "\n",
    "        # Initialize weights, by first building list of all weight matrix shapes.\n",
    "        n_in = n_inputs\n",
    "        shapes = []\n",
    "        for nh in self.n_hiddens_per_layer:\n",
    "            shapes.append((n_in + 1, nh))\n",
    "            n_in = nh\n",
    "        shapes.append((n_in + 1, n_outputs))\n",
    "\n",
    "        # self.all_weights:  vector of all weights\n",
    "        # self.Ws: list of weight matrices by layer\n",
    "        self.all_weights, self.Ws = self.make_weights_and_views(shapes)\n",
    "\n",
    "        # Define arrays to hold gradient values.\n",
    "        # One array for each W array with same shape.\n",
    "        self.all_gradients, self.dE_dWs = self.make_weights_and_views(shapes)\n",
    "\n",
    "        self.trained = False\n",
    "        self.total_epochs = 0\n",
    "        self.error_trace = []\n",
    "        self.Xmeans = None\n",
    "        self.Xstds = None\n",
    "        self.Tmeans = None\n",
    "        self.Tstds = None\n",
    "\n",
    "\n",
    "    def make_weights_and_views(self, shapes):\n",
    "        # vector of all weights built by horizontally stacking flatenned matrices\n",
    "        # for each layer initialized with uniformly-distributed values.\n",
    "        all_weights = np.hstack([np.random.uniform(size=shape).flat / np.sqrt(shape[0])\n",
    "                                 for shape in shapes])\n",
    "        # Build list of views by reshaping corresponding elements from vector of all weights\n",
    "        # into correct shape for each layer.\n",
    "        views = []\n",
    "        start = 0\n",
    "        for shape in shapes:\n",
    "            size =shape[0] * shape[1]\n",
    "            views.append(all_weights[start:start + size].reshape(shape))\n",
    "            start += size\n",
    "        return all_weights, views\n",
    "\n",
    "\n",
    "    # Return string that shows how the constructor was called\n",
    "    def __repr__(self):\n",
    "        return f'{type(self).__name__}({self.n_inputs}, {self.n_hiddens_per_layer}, {self.n_outputs}, \\'{self.activation_function}\\')'\n",
    "\n",
    "\n",
    "    # Return string that is more informative to the user about the state of this neural network.\n",
    "    def __str__(self):\n",
    "        result = self.__repr__()\n",
    "        if len(self.error_trace) > 0:\n",
    "            return self.__repr__() + f' trained for {len(self.error_trace)} epochs, final training error {self.error_trace[-1]:.4f}'\n",
    "\n",
    "\n",
    "    def train(self, X, T, n_epochs, learning_rate, method='sgd', verbose=True):\n",
    "        # train: \n",
    "            # X: n_samples x n_inputs matrix of input samples, one per row\n",
    "            # T: n_samples x n_outputs matrix of target output values, one sample per row\n",
    "            # n_epochs: number of passes to take through all samples updating weights each pass\n",
    "            # learning_rate: factor controlling the step size of each update\n",
    "            # method: is either 'sgd' or 'adam'\n",
    "\n",
    "        # Setup standardization parameters\n",
    "        if self.Xmeans is None:\n",
    "            self.Xmeans = X.mean(axis=0)\n",
    "            self.Xstds = X.std(axis=0)\n",
    "            self.Xstds[self.Xstds == 0] = 1  # So we don't divide by zero when standardizing\n",
    "            self.Tmeans = T.mean(axis=0)\n",
    "            self.Tstds = T.std(axis=0)\n",
    "            \n",
    "        # Standardize X and T\n",
    "        X = (X - self.Xmeans) / self.Xstds\n",
    "        T = (T - self.Tmeans) / self.Tstds\n",
    "\n",
    "        # Instantiate Optimizers object by giving it vector of all weights\n",
    "        optimizer = optimizers.Optimizers(self.all_weights)\n",
    "\n",
    "        # Define function to convert value from error_f into error in original T units, \n",
    "        # but only if the network has a single output. Multiplying by self.Tstds for \n",
    "        # multiple outputs does not correctly unstandardize the error.\n",
    "        if len(self.Tstds) == 1:\n",
    "            error_convert_f = lambda err: (np.sqrt(err) * self.Tstds)[0] # to scalar\n",
    "        else:\n",
    "            error_convert_f = lambda err: np.sqrt(err)[0] # to scalar\n",
    "            \n",
    "\n",
    "        if method == 'sgd':\n",
    "\n",
    "            error_trace = optimizer.sgd(self.error_f, self.gradient_f,\n",
    "                                        fargs=[X, T], n_epochs=n_epochs,\n",
    "                                        learning_rate=learning_rate,\n",
    "                                        verbose=True,\n",
    "                                        error_convert_f=error_convert_f)\n",
    "\n",
    "        elif method == 'adam':\n",
    "\n",
    "            error_trace = optimizer.adam(self.error_f, self.gradient_f,\n",
    "                                         fargs=[X, T], n_epochs=n_epochs,\n",
    "                                         learning_rate=learning_rate,\n",
    "                                         verbose=True,\n",
    "                                         error_convert_f=error_convert_f)\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"method must be 'sgd' or 'adam'\")\n",
    "        \n",
    "        self.error_trace = error_trace\n",
    "\n",
    "        # Return neural network object to allow applying other methods after training.\n",
    "        #  Example:    Y = nnet.train(X, T, 100, 0.01).use(X)\n",
    "        return self\n",
    "\n",
    "    def relu(self, s):\n",
    "        s[s < 0] = 0\n",
    "        return s\n",
    "\n",
    "    def grad_relu(self, s):\n",
    "        return (s > 0).astype(int)\n",
    "    \n",
    "    def forward_pass(self, X):\n",
    "        '''X assumed already standardized. Output returned as standardized.'''\n",
    "        self.Ys = [X]\n",
    "        for W in self.Ws[:-1]:\n",
    "            if self.activation_function == 'relu':\n",
    "                self.Ys.append(self.relu(self.Ys[-1] @ W[1:, :] + W[0:1, :]))\n",
    "            else:\n",
    "                self.Ys.append(np.tanh(self.Ys[-1] @ W[1:, :] + W[0:1, :]))\n",
    "        last_W = self.Ws[-1]\n",
    "        self.Ys.append(self.Ys[-1] @ last_W[1:, :] + last_W[0:1, :])\n",
    "        return self.Ys\n",
    "\n",
    "    # Function to be minimized by optimizer method, mean squared error\n",
    "    def error_f(self, X, T):\n",
    "        Ys = self.forward_pass(X)\n",
    "        mean_sq_error = np.mean((T - Ys[-1]) ** 2)\n",
    "        return mean_sq_error\n",
    "\n",
    "    # Gradient of function to be minimized for use by optimizer method\n",
    "    def gradient_f(self, X, T):\n",
    "        '''Assumes forward_pass just called with layer outputs in self.Ys.'''\n",
    "        error = T - self.Ys[-1]\n",
    "        n_samples = X.shape[0]\n",
    "        n_outputs = T.shape[1]\n",
    "        delta = - error / (n_samples * n_outputs)\n",
    "        n_layers = len(self.n_hiddens_per_layer) + 1\n",
    "        # Step backwards through the layers to back-propagate the error (delta)\n",
    "        for layeri in range(n_layers - 1, -1, -1):\n",
    "            # gradient of all but bias weights\n",
    "            self.dE_dWs[layeri][1:, :] = self.Ys[layeri].T @ delta\n",
    "            # gradient of just the bias weights\n",
    "            self.dE_dWs[layeri][0:1, :] = np.sum(delta, 0)\n",
    "            # Back-propagate this layer's delta to previous layer\n",
    "            if self.activation_function == 'relu':\n",
    "                delta = delta @ self.Ws[layeri][1:, :].T * self.grad_relu(self.Ys[layeri])\n",
    "            else:\n",
    "                delta = delta @ self.Ws[layeri][1:, :].T * (1 - self.Ys[layeri] ** 2)\n",
    "        return self.all_gradients\n",
    "\n",
    "    def use(self, X):\n",
    "        '''X assumed to not be standardized'''\n",
    "        # Standardize X\n",
    "        X = (X - self.Xmeans) / self.Xstds\n",
    "        Ys = self.forward_pass(X)\n",
    "        Y = Ys[-1]\n",
    "        # Unstandardize output Y before returning it\n",
    "        return Y * self.Tstds + self.Tmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd93cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam: Epoch 25 Error=0.25596\n",
      "Adam: Epoch 50 Error=0.22840\n",
      "Adam: Epoch 75 Error=0.20858\n",
      "Adam: Epoch 100 Error=0.18258\n",
      "Adam: Epoch 125 Error=0.14746\n",
      "Adam: Epoch 150 Error=0.10728\n",
      "Adam: Epoch 175 Error=0.07490\n",
      "Adam: Epoch 200 Error=0.05585\n",
      "Adam: Epoch 225 Error=0.04427\n",
      "Adam: Epoch 250 Error=0.03650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27b06045a60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from A4: Classification of Hand-Drawn Digits\n",
    "X = np.arange(100).reshape((-1, 1))\n",
    "T = (X - 20) ** 3 / 300000\n",
    "\n",
    "hiddens = [10]\n",
    "nnet = NeuralNetwork(X.shape[1], hiddens, T.shape[1])\n",
    "nnet.train(X, T, 250, 0.01, method='adam')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(nnet.error_trace)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(T, label='T')\n",
    "plt.plot(nnet.use(X), label='Y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d97190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from my A4: Classification of Hand-Drawn Digits\n",
    "class NeuralNetworkClassifier(NeuralNetwork):\n",
    "    \n",
    "    def makeIndicatorVars(self, T):\n",
    "        # Make sure T is two-dimensional. Should be nSamples x 1.\n",
    "        if T.ndim == 1:\n",
    "            T = T.reshape((-1, 1))\n",
    "        # print('makeIndicatorvars T: ', (T == np.unique(T)).astype(int).shape)\n",
    "        return (T == np.unique(T)).astype(int)\n",
    "    \n",
    "    def softmax(self, X):\n",
    "        fs = np.exp(X)\n",
    "        denom = np.sum(fs, axis=1).reshape((-1,1))\n",
    "        gs = fs / denom\n",
    "        return gs\n",
    "    \n",
    "    def train(self, X, T, n_epochs, learning_rate, method='sgd', verbose=True):\n",
    "        # Setup standardization parameters\n",
    "        self.labels = np.unique(T)\n",
    "        # print(\"self.labels: \", self.labels)\n",
    "        \n",
    "        if self.Xmeans is None:\n",
    "            self.Xmeans = X.mean(axis=0)\n",
    "            self.Xstds = X.std(axis=0)\n",
    "            self.Xstds[self.Xstds == 0] = 1\n",
    "            Tcon = np.zeros(T.shape)\n",
    "            for i in range(len(T)):\n",
    "                for j in range(len(self.labels)):\n",
    "                    if T[i] == self.labels[j]:\n",
    "                        Tcon[i] = j\n",
    "            Tprint = np.hstack((Tcon, T))\n",
    "            # print(\"Tprint (are things labeled correctly?): \", Tprint)\n",
    "            self.Tmeans = Tcon.mean(axis=0)\n",
    "            # print(\"Tcon.mean in train: \", Tcon.mean(axis=0))\n",
    "            self.Tstds = Tcon.std(axis=0)\n",
    "        \n",
    "        # Standardize X\n",
    "        X = (X - self.Xmeans) / self.Xstds\n",
    "        TI = self.makeIndicatorVars(T)\n",
    "        \n",
    "        optimizer = optimizers.Optimizers(self.all_weights)\n",
    "        to_likelihood = lambda nll: np.exp(-nll)\n",
    "        if method == 'adam':\n",
    "            likelihood_trace = optimizer.adam(self.error_f, self.gradient_f, fargs=[X,TI],\n",
    "                                          n_epochs=n_epochs, learning_rate=learning_rate, verbose=verbose, error_convert_f=to_likelihood)\n",
    "        elif method == 'sgd':\n",
    "            likelihood_trace = optimizer.sgd(self.error_f, self.gradient_f, fargs=[X,TI],\n",
    "                                          n_epochs=n_epochs, learning_rate=learning_rate, verbose=verbose, error_convert_f=to_likelihood)\n",
    "        else:\n",
    "            raise Exception(\"method must be 'sgd' or 'adam'\")\n",
    "        self.error_trace = likelihood_trace\n",
    "        return self\n",
    "        \n",
    "\n",
    "    def error_f(self, X, T): # neg_log_likelihood\n",
    "        Ys = self.forward_pass(X)\n",
    "        Ysm = self.softmax(Ys[-1])\n",
    "        return - np.mean(T * np.log(Ysm))\n",
    "\n",
    "    def gradient_f(self, X, T): #gradient_neg_log_likelihood\n",
    "        '''Assumes forward_pass just called with layer outputs in self.Ys.'''\n",
    "        error = T - self.softmax(self.Ys[-1])\n",
    "        n_samples = X.shape[0]\n",
    "        n_outputs = T.shape[1]\n",
    "        delta = - error / (n_samples * n_outputs)\n",
    "        n_layers = len(self.n_hiddens_per_layer) + 1\n",
    "        # Step backwards through the layers to back-propagate the error (delta)\n",
    "        for layeri in range(n_layers - 1, -1, -1):\n",
    "            # gradient of all but bias weights\n",
    "            self.dE_dWs[layeri][1:, :] = self.Ys[layeri].T @ delta\n",
    "            # gradient of just the bias weights\n",
    "            self.dE_dWs[layeri][0:1, :] = np.sum(delta, 0)\n",
    "            #  Back-propagate this layer's delta to previous layer\n",
    "            if self.activation_function == 'relu':\n",
    "                delta = delta @ self.Ws[layeri][1:, :].T * self.grad_relu(self.Ys[layeri])\n",
    "            else:\n",
    "                delta = delta @ self.Ws[layeri][1:, :].T * (1 - self.Ys[layeri] ** 2)\n",
    "        return self.all_gradients\n",
    "    \n",
    "    def use(self, X):\n",
    "        # Standardize X\n",
    "        X = (X - self.Xmeans) / self.Xstds\n",
    "        Ys = self.forward_pass(X)\n",
    "        labeled_data = []\n",
    "        probs = []\n",
    "        data = Ys[-1]\n",
    "        for i in range(len(data)):\n",
    "            labeled_data.append(self.labels[np.argmax(np.exp(data[i])/np.sum(np.exp(data[i])))])\n",
    "            probs.append(np.exp(data[i])/np.sum(np.exp(data[i])))\n",
    "            # print(\"data[i]: \", data[i])\n",
    "            # print(\"np.argmax(data[i]): \", np.argmax(data[i]))\n",
    "            # print(\"i: \", i, \"label: \", self.labels[np.argmax(data[i])])\n",
    "            # print(\"probs: \", np.exp(data[i])/np.sum(np.exp(data[i])))\n",
    "        ret_data = np.array(labeled_data).reshape((-1,1))\n",
    "        ret_probs = np.array(probs)\n",
    "        return ret_data, ret_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f3fc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from A4: Classification of Hand-Drawn Digits\n",
    "X = np.arange(100).reshape((-1, 1))\n",
    "T = X.copy()\n",
    "T[T <= 25] = 25\n",
    "T[np.logical_and(25 < T, T <= 75)] = 75\n",
    "T[T > 75] = 100\n",
    "\n",
    "plt.plot(X, T, 'o-')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Class');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6f34f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam: Epoch 20 Error=0.79836\n",
      "Adam: Epoch 40 Error=0.87032\n",
      "Adam: Epoch 60 Error=0.91574\n",
      "Adam: Epoch 80 Error=0.93984\n",
      "Adam: Epoch 100 Error=0.95264\n",
      "Adam: Epoch 120 Error=0.96034\n",
      "Adam: Epoch 140 Error=0.96553\n",
      "Adam: Epoch 160 Error=0.96931\n",
      "Adam: Epoch 180 Error=0.97222\n",
      "Adam: Epoch 200 Error=0.97454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27b0686ca60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from A4: Classification of Hand-Drawn Digits\n",
    "\n",
    "hiddens = [10]\n",
    "nnet = NeuralNetworkClassifier(X.shape[1], hiddens, len(np.unique(T)))\n",
    "nnet.train(X, T, 200, 0.01, method='adam', verbose=True)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(nnet.error_trace)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Likelihood')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(T + 5, 'o-', label='T + 5')  # to see, when predicted overlap T very closely\n",
    "plt.plot(nnet.use(X)[0], 'o-', label='Y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98930e3a",
   "metadata": {},
   "source": [
    "Ok, everything is working as planned. Just checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ca567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13028, 69)\n"
     ]
    }
   ],
   "source": [
    "data_arr = data.to_numpy()\n",
    "print(data_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8542e0bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vrl'] (13028, 1)\n",
      "[0] (13028, 1)\n",
      "64 (13028, 64)\n",
      "[0.01654 0.01203 0.0005  0.00351 0.01203 0.03208 0.001   0.0401  0.00551\n",
      " 0.02005 0.00752 0.02506 0.01103 0.0411  0.00902 0.03308 0.01003 0.05013\n",
      " 0.01554 0.01103 0.02356 0.03208 0.01203 0.00501 0.01003 0.01203 0.03158\n",
      " 0.01905 0.02456 0.01353 0.02155 0.00251 0.00652 0.0015  0.01554 0.00501\n",
      " 0.02105 0.00902 0.01053 0.00501 0.02256 0.00301 0.03108 0.00401 0.02607\n",
      " 0.00251 0.01153 0.00501 0.02356 0.01053 0.0386  0.00401 0.00702 0.00401\n",
      " 0.00451 0.01303 0.03559 0.01003 0.04612 0.01203 0.04361 0.00251 0.0005\n",
      " 0.     ]\n"
     ]
    }
   ],
   "source": [
    "# extract what we need\n",
    "# ignoring SpeciesID, Ncodons, and SpeciesName\n",
    "T_kingdoms = np.reshape(data_arr[:, 0], ((-1,1))) # kingdoms\n",
    "T_DNAtype = np.reshape(data_arr[:, 1], ((-1,1))) # DNAtype\n",
    "X_codons = data_arr[:, 5:69].astype('float32') # codon frequencies...needed to be converted for code to work\n",
    "print(T_kingdoms[0], T_kingdoms.shape)\n",
    "print(T_DNAtype[0], T_DNAtype.shape)\n",
    "print(len(X_codons[0]), X_codons.shape)\n",
    "print(X_codons[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0914fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from my A2: Multilayer Neural Networks for Nonlinear Regression\n",
    "def partition(X, T, n_folds, random_shuffle=True):\n",
    "    np.random.seed(42)\n",
    "    rows = np.arange(X.shape[0])\n",
    "    np.random.shuffle(rows)\n",
    "    X = X[rows, :]\n",
    "    T = T[rows, :]\n",
    "    n_samples = X.shape[0]\n",
    "    n_per_fold = n_samples // n_folds\n",
    "    n_last_fold = n_samples - n_per_fold * (n_folds - 1)\n",
    "    folds = []\n",
    "    start = 0\n",
    "    for foldi in range(n_folds - 1):\n",
    "        folds.append( (X[start:start + n_per_fold, :], T[start:start + n_per_fold, :]) )\n",
    "        start += n_per_fold\n",
    "    folds.append( (X[start:, :], T[start:, :]) )\n",
    "    Xvalidate, Tvalidate = folds[0]\n",
    "    Xtest, Ttest = folds[1]\n",
    "    Xtrain, Ttrain = np.vstack([X for (X, _) in folds[2:]]), np.vstack([T for (_, T) in folds[2:]])\n",
    "    return Xtrain, Ttrain, Xvalidate, Tvalidate, Xtest, Ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42835805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data up into train, validate, and test\n",
    "n_folds = 5\n",
    "Xtrain_kingdom, Ttrain_kingdom, Xval_kingdom, Tval_kingdom, Xtest_kingdom, Ttest_kingdom = partition(X_codons, T_kingdoms, n_folds, random_shuffle=True)\n",
    "Xtrain_DNAtype, Ttrain_DNAtype, Xval_DNAtype, Tval_DNAtype, Xtest_DNAtype, Ttest_DNAtype = partition(X_codons, T_DNAtype, n_folds, random_shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53916fc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# based off of my A4: Classification of Hand-Drawn Digits\n",
    "import time\n",
    "\n",
    "def run_experiments(hl_structures, classes, epochs, learning_rates, act_func, opt, Xtrain, Ttrain, Xval, Tval, Xtest, Ttest):\n",
    "    table = []\n",
    "    prog_total = len(hl_structures) * len(epochs) * len(learning_rates) * len(act_func) * len(opt)\n",
    "    prog_curr = 1\n",
    "    for h in range(len(hl_structures)):\n",
    "        for e in range(len(epochs)):\n",
    "            for lr in range(len(learning_rates)):\n",
    "                for a in range(len(act_func)):\n",
    "                    for o in range(len(opt)):\n",
    "                        start = time.time()\n",
    "                        print(\"Progress: \", prog_curr, \"/\", prog_total)\n",
    "                        nnet = NeuralNetworkClassifier(Xtrain.shape[1], hl_structures[h], len(classes), act_func[a])\n",
    "                        nnet.train(Xtrain, Ttrain, epochs[e], learning_rates[lr], method=opt[o], verbose=False)\n",
    "                        end = time.time()\n",
    "                        total_time = str(end - start)\n",
    "                        Xtrain_res, Xtrain_prob = nnet.use(Xtrain)\n",
    "                        Xval_res, Xval_prob = nnet.use(Xval)\n",
    "                        Xtest_res, Xtest_prob = nnet.use(Xtest)\n",
    "                        train_acc = 100 * np.mean(Xtrain_res == Ttrain)\n",
    "                        val_acc = 100 * np.mean(Xval_res == Tval)\n",
    "                        test_acc = 100 * np.mean(Xtest_res == Ttest)\n",
    "                        table.append([hl_structures[h],\n",
    "                                      epochs[e],\n",
    "                                      learning_rates[lr],\n",
    "                                      act_func[a],\n",
    "                                      opt[o],\n",
    "                                      train_acc,\n",
    "                                      val_acc,\n",
    "                                      test_acc,\n",
    "                                      total_time])\n",
    "                        prog_curr += 1\n",
    "    column_labels = ['Hidden Layers',\n",
    "                     'Epochs',\n",
    "                     'Learning Rate',\n",
    "                     'Activation Function',\n",
    "                     'Optimization',\n",
    "                     'Train',\n",
    "                     'Validate',\n",
    "                     'Test',\n",
    "                     'Training Time']\n",
    "    results = pandas.DataFrame(table, columns=column_labels)\n",
    "    best_arch = results.loc[results['Validate'] == results['Validate'].max()]\n",
    "    # we are considering the architecture with the best validate accuracy to be the best overall\n",
    "    return results, best_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dafef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment parameters\n",
    "hl_structures = [[],\n",
    "                 [10],\n",
    "                 [10,10],\n",
    "                 [50],\n",
    "                 [50,50],\n",
    "                 [100],\n",
    "                 [100,50,10]]\n",
    "epochs = [50, 500]\n",
    "learning_rates = [0.01, 0.001, 0.0005]\n",
    "activation_functions = ['tanh', 'relu']\n",
    "optimizations = ['sgd', 'adam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0821e8b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:  1 / 168\n",
      "Progress:  2 / 168\n",
      "Progress:  3 / 168\n",
      "Progress:  4 / 168\n",
      "Progress:  5 / 168\n",
      "Progress:  6 / 168\n",
      "Progress:  7 / 168\n",
      "Progress:  8 / 168\n",
      "Progress:  9 / 168\n",
      "Progress:  10 / 168\n",
      "Progress:  11 / 168\n",
      "Progress:  12 / 168\n",
      "Progress:  13 / 168\n",
      "Progress:  14 / 168\n",
      "Progress:  15 / 168\n",
      "Progress:  16 / 168\n",
      "Progress:  17 / 168\n",
      "Progress:  18 / 168\n",
      "Progress:  19 / 168\n",
      "Progress:  20 / 168\n",
      "Progress:  21 / 168\n",
      "Progress:  22 / 168\n",
      "Progress:  23 / 168\n",
      "Progress:  24 / 168\n",
      "Progress:  25 / 168\n",
      "Progress:  26 / 168\n",
      "Progress:  27 / 168\n",
      "Progress:  28 / 168\n",
      "Progress:  29 / 168\n",
      "Progress:  30 / 168\n",
      "Progress:  31 / 168\n",
      "Progress:  32 / 168\n",
      "Progress:  33 / 168\n",
      "Progress:  34 / 168\n",
      "Progress:  35 / 168\n",
      "Progress:  36 / 168\n",
      "Progress:  37 / 168\n",
      "Progress:  38 / 168\n",
      "Progress:  39 / 168\n",
      "Progress:  40 / 168\n",
      "Progress:  41 / 168\n",
      "Progress:  42 / 168\n",
      "Progress:  43 / 168\n",
      "Progress:  44 / 168\n",
      "Progress:  45 / 168\n",
      "Progress:  46 / 168\n",
      "Progress:  47 / 168\n",
      "Progress:  48 / 168\n",
      "Progress:  49 / 168\n",
      "Progress:  50 / 168\n",
      "Progress:  51 / 168\n",
      "Progress:  52 / 168\n",
      "Progress:  53 / 168\n",
      "Progress:  54 / 168\n",
      "Progress:  55 / 168\n",
      "Progress:  56 / 168\n",
      "Progress:  57 / 168\n",
      "Progress:  58 / 168\n",
      "Progress:  59 / 168\n",
      "Progress:  60 / 168\n",
      "Progress:  61 / 168\n",
      "Progress:  62 / 168\n",
      "Progress:  63 / 168\n",
      "Progress:  64 / 168\n",
      "Progress:  65 / 168\n",
      "Progress:  66 / 168\n",
      "Progress:  67 / 168\n",
      "Progress:  68 / 168\n",
      "Progress:  69 / 168\n",
      "Progress:  70 / 168\n",
      "Progress:  71 / 168\n",
      "Progress:  72 / 168\n",
      "Progress:  73 / 168\n",
      "Progress:  74 / 168\n",
      "Progress:  75 / 168\n",
      "Progress:  76 / 168\n",
      "Progress:  77 / 168\n",
      "Progress:  78 / 168\n",
      "Progress:  79 / 168\n",
      "Progress:  80 / 168\n",
      "Progress:  81 / 168\n",
      "Progress:  82 / 168\n",
      "Progress:  83 / 168\n",
      "Progress:  84 / 168\n",
      "Progress:  85 / 168\n",
      "Progress:  86 / 168\n",
      "Progress:  87 / 168\n",
      "Progress:  88 / 168\n",
      "Progress:  89 / 168\n",
      "Progress:  90 / 168\n",
      "Progress:  91 / 168\n",
      "Progress:  92 / 168\n",
      "Progress:  93 / 168\n",
      "Progress:  94 / 168\n",
      "Progress:  95 / 168\n",
      "Progress:  96 / 168\n",
      "Progress:  97 / 168\n",
      "Progress:  98 / 168\n",
      "Progress:  99 / 168\n",
      "Progress:  100 / 168\n",
      "Progress:  101 / 168\n",
      "Progress:  102 / 168\n",
      "Progress:  103 / 168\n",
      "Progress:  104 / 168\n",
      "Progress:  105 / 168\n",
      "Progress:  106 / 168\n",
      "Progress:  107 / 168\n",
      "Progress:  108 / 168\n",
      "Progress:  109 / 168\n",
      "Progress:  110 / 168\n",
      "Progress:  111 / 168\n",
      "Progress:  112 / 168\n",
      "Progress:  113 / 168\n",
      "Progress:  114 / 168\n",
      "Progress:  115 / 168\n",
      "Progress:  116 / 168\n",
      "Progress:  117 / 168\n",
      "Progress:  118 / 168\n",
      "Progress:  119 / 168\n",
      "Progress:  120 / 168\n",
      "Progress:  121 / 168\n",
      "Progress:  122 / 168\n",
      "Progress:  123 / 168\n",
      "Progress:  124 / 168\n",
      "Progress:  125 / 168\n",
      "Progress:  126 / 168\n",
      "Progress:  127 / 168\n",
      "Progress:  128 / 168\n",
      "Progress:  129 / 168\n",
      "Progress:  130 / 168\n",
      "Progress:  131 / 168\n",
      "Progress:  132 / 168\n",
      "Progress:  133 / 168\n",
      "Progress:  134 / 168\n",
      "Progress:  135 / 168\n",
      "Progress:  136 / 168\n",
      "Progress:  137 / 168\n",
      "Progress:  138 / 168\n",
      "Progress:  139 / 168\n",
      "Progress:  140 / 168\n",
      "Progress:  141 / 168\n",
      "Progress:  142 / 168\n",
      "Progress:  143 / 168\n",
      "Progress:  144 / 168\n",
      "Progress:  145 / 168\n",
      "Progress:  146 / 168\n",
      "Progress:  147 / 168\n",
      "Progress:  148 / 168\n",
      "Progress:  149 / 168\n",
      "Progress:  150 / 168\n",
      "Progress:  151 / 168\n",
      "Progress:  152 / 168\n",
      "Progress:  153 / 168\n",
      "Progress:  154 / 168\n",
      "Progress:  155 / 168\n",
      "Progress:  156 / 168\n",
      "Progress:  157 / 168\n",
      "Progress:  158 / 168\n",
      "Progress:  159 / 168\n",
      "Progress:  160 / 168\n",
      "Progress:  161 / 168\n",
      "Progress:  162 / 168\n",
      "Progress:  163 / 168\n",
      "Progress:  164 / 168\n",
      "Progress:  165 / 168\n",
      "Progress:  166 / 168\n",
      "Progress:  167 / 168\n",
      "Progress:  168 / 168\n",
      "Best architecture for kingdoms:      Hidden Layers  Epochs  Learning Rate Activation Function Optimization  \\\n",
      "135         [100]     500           0.01                relu         adam   \n",
      "\n",
      "     Train   Validate       Test      Training Time  \n",
      "135  100.0  92.207294  93.358925  24.87000060081482  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Activation Function</th>\n",
       "      <th>Optimization</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validate</th>\n",
       "      <th>Test</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>20.069071</td>\n",
       "      <td>18.387716</td>\n",
       "      <td>19.692898</td>\n",
       "      <td>1.1215004920959473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>81.235610</td>\n",
       "      <td>79.654511</td>\n",
       "      <td>80.575816</td>\n",
       "      <td>1.1149990558624268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>13.891021</td>\n",
       "      <td>14.088292</td>\n",
       "      <td>13.742802</td>\n",
       "      <td>1.3595001697540283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>80.596060</td>\n",
       "      <td>78.963532</td>\n",
       "      <td>80.383877</td>\n",
       "      <td>1.1985011100769043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>5.743157</td>\n",
       "      <td>5.374280</td>\n",
       "      <td>6.065259</td>\n",
       "      <td>1.2365021705627441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>[100, 50, 10]</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>94.141724</td>\n",
       "      <td>89.174664</td>\n",
       "      <td>89.328215</td>\n",
       "      <td>32.48100018501282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>[100, 50, 10]</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>12.471220</td>\n",
       "      <td>11.938580</td>\n",
       "      <td>13.320537</td>\n",
       "      <td>39.09650015830994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>[100, 50, 10]</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>81.862369</td>\n",
       "      <td>78.925144</td>\n",
       "      <td>80.230326</td>\n",
       "      <td>36.28349947929382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>[100, 50, 10]</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>22.384241</td>\n",
       "      <td>22.495202</td>\n",
       "      <td>22.418426</td>\n",
       "      <td>26.431999444961548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[100, 50, 10]</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>88.436940</td>\n",
       "      <td>85.950096</td>\n",
       "      <td>87.332054</td>\n",
       "      <td>22.078998804092407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Hidden Layers  Epochs  Learning Rate Activation Function Optimization  \\\n",
       "0               []      50         0.0100                tanh          sgd   \n",
       "1               []      50         0.0100                tanh         adam   \n",
       "2               []      50         0.0100                relu          sgd   \n",
       "3               []      50         0.0100                relu         adam   \n",
       "4               []      50         0.0010                tanh          sgd   \n",
       "..             ...     ...            ...                 ...          ...   \n",
       "163  [100, 50, 10]     500         0.0010                relu         adam   \n",
       "164  [100, 50, 10]     500         0.0005                tanh          sgd   \n",
       "165  [100, 50, 10]     500         0.0005                tanh         adam   \n",
       "166  [100, 50, 10]     500         0.0005                relu          sgd   \n",
       "167  [100, 50, 10]     500         0.0005                relu         adam   \n",
       "\n",
       "         Train   Validate       Test       Training Time  \n",
       "0    20.069071  18.387716  19.692898  1.1215004920959473  \n",
       "1    81.235610  79.654511  80.575816  1.1149990558624268  \n",
       "2    13.891021  14.088292  13.742802  1.3595001697540283  \n",
       "3    80.596060  78.963532  80.383877  1.1985011100769043  \n",
       "4     5.743157   5.374280   6.065259  1.2365021705627441  \n",
       "..         ...        ...        ...                 ...  \n",
       "163  94.141724  89.174664  89.328215   32.48100018501282  \n",
       "164  12.471220  11.938580  13.320537   39.09650015830994  \n",
       "165  81.862369  78.925144  80.230326   36.28349947929382  \n",
       "166  22.384241  22.495202  22.418426  26.431999444961548  \n",
       "167  88.436940  85.950096  87.332054  22.078998804092407  \n",
       "\n",
       "[168 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_res_kingdom, exp_best_kingdom_arch = run_experiments(hl_structures,\n",
    "                                                         np.unique(T_kingdoms),\n",
    "                                                         epochs,\n",
    "                                                         learning_rates,\n",
    "                                                         activation_functions,\n",
    "                                                         optimizations,\n",
    "                                                         Xtrain_kingdom,\n",
    "                                                         Ttrain_kingdom,\n",
    "                                                         Xval_kingdom,\n",
    "                                                         Tval_kingdom,\n",
    "                                                         Xtest_kingdom,\n",
    "                                                         Ttest_kingdom)\n",
    "\n",
    "print(\"Best architecture for kingdoms: \", exp_best_kingdom_arch)\n",
    "exp_res_kingdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71de9f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:  1 / 168\n",
      "Progress:  2 / 168\n",
      "Progress:  3 / 168\n",
      "Progress:  4 / 168\n",
      "Progress:  5 / 168\n",
      "Progress:  6 / 168\n",
      "Progress:  7 / 168\n",
      "Progress:  8 / 168\n",
      "Progress:  9 / 168\n",
      "Progress:  10 / 168\n",
      "Progress:  11 / 168\n",
      "Progress:  12 / 168\n",
      "Progress:  13 / 168\n",
      "Progress:  14 / 168\n",
      "Progress:  15 / 168\n",
      "Progress:  16 / 168\n",
      "Progress:  17 / 168\n",
      "Progress:  18 / 168\n",
      "Progress:  19 / 168\n",
      "Progress:  20 / 168\n",
      "Progress:  21 / 168\n",
      "Progress:  22 / 168\n",
      "Progress:  23 / 168\n",
      "Progress:  24 / 168\n",
      "Progress:  25 / 168\n",
      "Progress:  26 / 168\n",
      "Progress:  27 / 168\n",
      "Progress:  28 / 168\n",
      "Progress:  29 / 168\n",
      "Progress:  30 / 168\n",
      "Progress:  31 / 168\n",
      "Progress:  32 / 168\n",
      "Progress:  33 / 168\n",
      "Progress:  34 / 168\n",
      "Progress:  35 / 168\n",
      "Progress:  36 / 168\n",
      "Progress:  37 / 168\n",
      "Progress:  38 / 168\n",
      "Progress:  39 / 168\n",
      "Progress:  40 / 168\n",
      "Progress:  41 / 168\n",
      "Progress:  42 / 168\n",
      "Progress:  43 / 168\n",
      "Progress:  44 / 168\n",
      "Progress:  45 / 168\n",
      "Progress:  46 / 168\n",
      "Progress:  47 / 168\n",
      "Progress:  48 / 168\n",
      "Progress:  49 / 168\n",
      "Progress:  50 / 168\n",
      "Progress:  51 / 168\n",
      "Progress:  52 / 168\n",
      "Progress:  53 / 168\n",
      "Progress:  54 / 168\n",
      "Progress:  55 / 168\n",
      "Progress:  56 / 168\n",
      "Progress:  57 / 168\n",
      "Progress:  58 / 168\n",
      "Progress:  59 / 168\n",
      "Progress:  60 / 168\n",
      "Progress:  61 / 168\n",
      "Progress:  62 / 168\n",
      "Progress:  63 / 168\n",
      "Progress:  64 / 168\n",
      "Progress:  65 / 168\n",
      "Progress:  66 / 168\n",
      "Progress:  67 / 168\n",
      "Progress:  68 / 168\n",
      "Progress:  69 / 168\n",
      "Progress:  70 / 168\n",
      "Progress:  71 / 168\n",
      "Progress:  72 / 168\n",
      "Progress:  73 / 168\n",
      "Progress:  74 / 168\n",
      "Progress:  75 / 168\n",
      "Progress:  76 / 168\n",
      "Progress:  77 / 168\n",
      "Progress:  78 / 168\n",
      "Progress:  79 / 168\n",
      "Progress:  80 / 168\n",
      "Progress:  81 / 168\n",
      "Progress:  82 / 168\n",
      "Progress:  83 / 168\n",
      "Progress:  84 / 168\n",
      "Progress:  85 / 168\n",
      "Progress:  86 / 168\n",
      "Progress:  87 / 168\n",
      "Progress:  88 / 168\n",
      "Progress:  89 / 168\n",
      "Progress:  90 / 168\n",
      "Progress:  91 / 168\n",
      "Progress:  92 / 168\n",
      "Progress:  93 / 168\n",
      "Progress:  94 / 168\n",
      "Progress:  95 / 168\n",
      "Progress:  96 / 168\n",
      "Progress:  97 / 168\n",
      "Progress:  98 / 168\n",
      "Progress:  99 / 168\n",
      "Progress:  100 / 168\n",
      "Progress:  101 / 168\n",
      "Progress:  102 / 168\n",
      "Progress:  103 / 168\n",
      "Progress:  104 / 168\n",
      "Progress:  105 / 168\n",
      "Progress:  106 / 168\n",
      "Progress:  107 / 168\n",
      "Progress:  108 / 168\n",
      "Progress:  109 / 168\n",
      "Progress:  110 / 168\n",
      "Progress:  111 / 168\n",
      "Progress:  112 / 168\n",
      "Progress:  113 / 168\n",
      "Progress:  114 / 168\n",
      "Progress:  115 / 168\n",
      "Progress:  116 / 168\n",
      "Progress:  117 / 168\n",
      "Progress:  118 / 168\n",
      "Progress:  119 / 168\n",
      "Progress:  120 / 168\n",
      "Progress:  121 / 168\n",
      "Progress:  122 / 168\n",
      "Progress:  123 / 168\n",
      "Progress:  124 / 168\n",
      "Progress:  125 / 168\n",
      "Progress:  126 / 168\n",
      "Progress:  127 / 168\n",
      "Progress:  128 / 168\n",
      "Progress:  129 / 168\n",
      "Progress:  130 / 168\n",
      "Progress:  131 / 168\n",
      "Progress:  132 / 168\n",
      "Progress:  133 / 168\n",
      "Progress:  134 / 168\n",
      "Progress:  135 / 168\n",
      "Progress:  136 / 168\n",
      "Progress:  137 / 168\n",
      "Progress:  138 / 168\n",
      "Progress:  139 / 168\n",
      "Progress:  140 / 168\n",
      "Progress:  141 / 168\n",
      "Progress:  142 / 168\n",
      "Progress:  143 / 168\n",
      "Progress:  144 / 168\n",
      "Progress:  145 / 168\n",
      "Progress:  146 / 168\n",
      "Progress:  147 / 168\n",
      "Progress:  148 / 168\n",
      "Progress:  149 / 168\n",
      "Progress:  150 / 168\n",
      "Progress:  151 / 168\n",
      "Progress:  152 / 168\n",
      "Progress:  153 / 168\n",
      "Progress:  154 / 168\n",
      "Progress:  155 / 168\n",
      "Progress:  156 / 168\n",
      "Progress:  157 / 168\n",
      "Progress:  158 / 168\n",
      "Progress:  159 / 168\n",
      "Progress:  160 / 168\n",
      "Progress:  161 / 168\n",
      "Progress:  162 / 168\n",
      "Progress:  163 / 168\n",
      "Progress:  164 / 168\n",
      "Progress:  165 / 168\n",
      "Progress:  166 / 168\n",
      "Progress:  167 / 168\n",
      "Progress:  168 / 168\n",
      "Best architecture for DNAtype:      Hidden Layers  Epochs  Learning Rate Activation Function Optimization  \\\n",
      "135         [100]     500           0.01                relu         adam   \n",
      "\n",
      "         Train   Validate       Test      Training Time  \n",
      "135  99.961627  99.309021  99.078695  21.19950270652771  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Activation Function</th>\n",
       "      <th>Optimization</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validate</th>\n",
       "      <th>Test</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>29.534408</td>\n",
       "      <td>28.752399</td>\n",
       "      <td>29.289827</td>\n",
       "      <td>0.7450013160705566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>96.891788</td>\n",
       "      <td>96.506718</td>\n",
       "      <td>96.506718</td>\n",
       "      <td>0.7640013694763184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>43.566129</td>\n",
       "      <td>43.838772</td>\n",
       "      <td>45.028791</td>\n",
       "      <td>0.7054991722106934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>96.904579</td>\n",
       "      <td>96.775432</td>\n",
       "      <td>96.737044</td>\n",
       "      <td>0.7140004634857178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>17.306216</td>\n",
       "      <td>16.161228</td>\n",
       "      <td>18.310940</td>\n",
       "      <td>0.714998722076416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>[100, 50, 10]</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>99.398823</td>\n",
       "      <td>99.001919</td>\n",
       "      <td>99.040307</td>\n",
       "      <td>29.942498683929443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>[100, 50, 10]</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.025582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076775</td>\n",
       "      <td>37.37349891662598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>[100, 50, 10]</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>99.488360</td>\n",
       "      <td>99.193858</td>\n",
       "      <td>99.078695</td>\n",
       "      <td>41.00350046157837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>[100, 50, 10]</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>relu</td>\n",
       "      <td>sgd</td>\n",
       "      <td>68.841136</td>\n",
       "      <td>70.134357</td>\n",
       "      <td>69.174664</td>\n",
       "      <td>24.498499155044556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[100, 50, 10]</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>92.977744</td>\n",
       "      <td>92.437620</td>\n",
       "      <td>92.936660</td>\n",
       "      <td>26.691500425338745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Hidden Layers  Epochs  Learning Rate Activation Function Optimization  \\\n",
       "0               []      50         0.0100                tanh          sgd   \n",
       "1               []      50         0.0100                tanh         adam   \n",
       "2               []      50         0.0100                relu          sgd   \n",
       "3               []      50         0.0100                relu         adam   \n",
       "4               []      50         0.0010                tanh          sgd   \n",
       "..             ...     ...            ...                 ...          ...   \n",
       "163  [100, 50, 10]     500         0.0010                relu         adam   \n",
       "164  [100, 50, 10]     500         0.0005                tanh          sgd   \n",
       "165  [100, 50, 10]     500         0.0005                tanh         adam   \n",
       "166  [100, 50, 10]     500         0.0005                relu          sgd   \n",
       "167  [100, 50, 10]     500         0.0005                relu         adam   \n",
       "\n",
       "         Train   Validate       Test       Training Time  \n",
       "0    29.534408  28.752399  29.289827  0.7450013160705566  \n",
       "1    96.891788  96.506718  96.506718  0.7640013694763184  \n",
       "2    43.566129  43.838772  45.028791  0.7054991722106934  \n",
       "3    96.904579  96.775432  96.737044  0.7140004634857178  \n",
       "4    17.306216  16.161228  18.310940   0.714998722076416  \n",
       "..         ...        ...        ...                 ...  \n",
       "163  99.398823  99.001919  99.040307  29.942498683929443  \n",
       "164   0.025582   0.000000   0.076775   37.37349891662598  \n",
       "165  99.488360  99.193858  99.078695   41.00350046157837  \n",
       "166  68.841136  70.134357  69.174664  24.498499155044556  \n",
       "167  92.977744  92.437620  92.936660  26.691500425338745  \n",
       "\n",
       "[168 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_res_DNAtype, exp_best_DNAtype_arch = run_experiments(hl_structures,\n",
    "                                                         np.unique(Ttrain_DNAtype),\n",
    "                                                         epochs,\n",
    "                                                         learning_rates,\n",
    "                                                         activation_functions,\n",
    "                                                         optimizations,\n",
    "                                                         Xtrain_DNAtype,\n",
    "                                                         Ttrain_DNAtype,\n",
    "                                                         Xval_DNAtype,\n",
    "                                                         Tval_DNAtype,\n",
    "                                                         Xtest_DNAtype,\n",
    "                                                         Ttest_DNAtype)\n",
    "\n",
    "print(\"Best architecture for DNAtype: \", exp_best_DNAtype_arch)\n",
    "exp_res_DNAtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a304367f",
   "metadata": {},
   "source": [
    "The best architecture for kingdom classification was:\n",
    "\n",
    "|  |Hidden Layers | Epochs | Learning Rate | Activation Function | Optimization | Train | Validate | Test | Time |\n",
    "|---|---|---|---|---|---|---|---|---|---|\n",
    "| 135 | [100] | 500 | 0.01 | relu | adam | 100.00000 | 92.207294 | 93.358925 | 24.87s |\n",
    "\n",
    "The best architecture for DNAtype classification was:\n",
    "\n",
    "|  |Hidden Layers | Epochs | Learning Rate | Activation Function | Optimization | Train | Validate | Test | Time |\n",
    "|---|---|---|---|---|---|---|---|---|---|\n",
    "| 135 | [100] | 500 | 0.01 | relu | adam | 99.961627 | 99.309021 | 99.078695 | 21.20s |\n",
    "\n",
    "The same architecture for both!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ac6ac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from A4: Classification of Hand-Drawn Digits\n",
    "def confusion_matrix(classes, test):\n",
    "    table = []\n",
    "    labels = np.unique(classes)\n",
    "    classes_con = np.zeros(classes.shape)\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(labels)):\n",
    "                if classes[i] == labels[j]:\n",
    "                    classes_con[i] = j\n",
    "    test_con = np.zeros(test.shape)\n",
    "    for i in range(len(test)):\n",
    "        for j in range(len(labels)):\n",
    "                if test[i] == labels[j]:\n",
    "                    test_con[i] = j\n",
    "    #print(\"classes_con: \", classes_con)\n",
    "    for true_class in range(len(labels)):\n",
    "        row = []\n",
    "        for predicted_class in range(len(labels)):\n",
    "            row.append(100 * np.mean(classes_con[test_con == true_class] == predicted_class))\n",
    "        table.append(row)\n",
    "    conf_matrix = pandas.DataFrame(table, index=labels, columns=labels)\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "260b296f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arc</th>\n",
       "      <th>bct</th>\n",
       "      <th>inv</th>\n",
       "      <th>mam</th>\n",
       "      <th>phg</th>\n",
       "      <th>plm</th>\n",
       "      <th>pln</th>\n",
       "      <th>pri</th>\n",
       "      <th>rod</th>\n",
       "      <th>vrl</th>\n",
       "      <th>vrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>arc</th>\n",
       "      <td>88.235294</td>\n",
       "      <td>11.764706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bct</th>\n",
       "      <td>0.684932</td>\n",
       "      <td>94.691781</td>\n",
       "      <td>0.513699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.883562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.054795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inv</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.831502</td>\n",
       "      <td>87.179487</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.959707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.732601</td>\n",
       "      <td>2.564103</td>\n",
       "      <td>0.366300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mam</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>2.678571</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phg</th>\n",
       "      <td>2.380952</td>\n",
       "      <td>11.904762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.952381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.380952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.380952</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plm</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pln</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.002004</td>\n",
       "      <td>2.204409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.386774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.605210</td>\n",
       "      <td>0.400802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pri</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.128205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.487179</td>\n",
       "      <td>2.564103</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>5.128205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rod</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vrl</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359066</td>\n",
       "      <td>1.795332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.436266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179533</td>\n",
       "      <td>95.870736</td>\n",
       "      <td>0.359066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vrt</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.136364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>1.136364</td>\n",
       "      <td>95.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           arc        bct        inv        mam        phg   plm        pln  \\\n",
       "arc  88.235294  11.764706   0.000000   0.000000   0.000000   0.0   0.000000   \n",
       "bct   0.684932  94.691781   0.513699   0.000000   1.883562   0.0   2.054795   \n",
       "inv   0.000000   1.831502  87.179487   0.366300   0.000000   0.0   6.959707   \n",
       "mam   0.000000   0.000000   0.000000  89.285714   0.000000   0.0   0.892857   \n",
       "phg   2.380952  11.904762   0.000000   0.000000  80.952381   0.0   2.380952   \n",
       "plm   0.000000  33.333333   0.000000   0.000000  16.666667  50.0   0.000000   \n",
       "pln   0.000000   1.002004   2.204409   0.000000   0.400802   0.0  93.386774   \n",
       "pri   0.000000   0.000000   0.000000   5.128205   0.000000   0.0   0.000000   \n",
       "rod   0.000000   0.000000   0.000000  16.666667   0.000000   0.0   0.000000   \n",
       "vrl   0.000000   0.359066   1.795332   0.000000   0.000000   0.0   1.436266   \n",
       "vrt   0.000000   0.000000   1.136364   0.454545   0.000000   0.0   0.454545   \n",
       "\n",
       "           pri        rod        vrl        vrt  \n",
       "arc   0.000000   0.000000   0.000000   0.000000  \n",
       "bct   0.000000   0.000000   0.000000   0.171233  \n",
       "inv   0.000000   0.732601   2.564103   0.366300  \n",
       "mam   2.678571   1.785714   1.785714   3.571429  \n",
       "phg   0.000000   0.000000   2.380952   0.000000  \n",
       "plm   0.000000   0.000000   0.000000   0.000000  \n",
       "pln   0.000000   0.000000   2.605210   0.400802  \n",
       "pri  79.487179   2.564103   7.692308   5.128205  \n",
       "rod   2.777778  77.777778   0.000000   2.777778  \n",
       "vrl   0.000000   0.179533  95.870736   0.359066  \n",
       "vrt   0.227273   0.681818   1.136364  95.909091  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the best architecture, how accurately can we predict kingdoms?\n",
    "kingdom_best = NeuralNetworkClassifier(Xtrain_kingdom.shape[1], [100], len(np.unique(T_kingdoms)), activation_function='relu')\n",
    "kingdom_best.train(Xtrain_kingdom, Ttrain_kingdom, 500, 0.01, method='adam', verbose=False)\n",
    "kingdom_best_classes, kingdom_best_probs = kingdom_best.use(Xtest_kingdom)\n",
    "kingdom_best_cm = confusion_matrix(kingdom_best_classes, Ttest_kingdom)\n",
    "kingdom_best_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34f8f58",
   "metadata": {},
   "source": [
    "The most misclassified kingdom was 'plm' (plasmid, 50.0). It was mislabeled as 'bct' (bacteria) 33.33% of the time and 'phg' (bacteriophage) 16.67% of the time. According to the National Human Genome Research Institute, a plasmid is \"a small circular DNA molecule found in bacteria and some other microscopic organisms\" (https://www.genome.gov/genetics-glossary/Plasmid). Mislabeling a plasmid as a bacteria or bacteriophage (\"a virus that infects bacteria\", https://www.khanacademy.org/science/biology/biology-of-viruses/virus-biology/a/bacteriophages) makes sense as they are all related to bacteria, with plasmids and bacteriophages being slightly more specific.\n",
    "\n",
    "Other misclassifications are also understandable as the kingdoms are related. For instance, rodents were classified correctly 77.78% of the time, but 16.67% of the time were 'misclassified' as mammals. The same could be said about primates: primates are mammals, and they are also vertebrates. In my opinion, this is a case of poor labeling by the source data, as rodents are technically mammals and vertebrates. I am interested to read more about the reasoning behind the labeling choices of the author.\n",
    "\n",
    "The most accurately classified kingdom was 'vrt' (vertebrates, 95.91). It is interesting to see that primates are misclassified as viral DNA 7.68% of the time. According to the Science up to 8% of DNA is of ancient viral origin (https://www.science.org/content/article/viral-fossils-our-dna-may-help-us-fight-infection), so this misclassification at that rate is to be expected. The 'vrl' (viral) kingdom was close behind with an accuracy of 95.87. It is encouraging that this classifier was able to identify viral DNA so well as this was one of the main goals of this experiment. With diseases mutating as quickly as they do it is important to be able to quickly identify potentially harmful DNA and quickly find similar relatives in order to appropriately develop effective treatments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aa92875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27b086dc5b0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# likelihood trace for kingdoms\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(kingdom_best.error_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4845c88a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.729584</td>\n",
       "      <td>0.162250</td>\n",
       "      <td>0.108167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171233</td>\n",
       "      <td>99.657534</td>\n",
       "      <td>0.171233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.439024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96.341463</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2         3          4      11\n",
       "0   99.729584   0.162250   0.108167  0.000000   0.000000    0.0\n",
       "1    0.171233  99.657534   0.171233  0.000000   0.000000    0.0\n",
       "2    2.439024   0.000000  96.341463  0.609756   0.609756    0.0\n",
       "3         NaN        NaN        NaN       NaN        NaN    NaN\n",
       "4   28.571429   0.000000  42.857143  0.000000  28.571429    0.0\n",
       "11   0.000000   0.000000   0.000000  0.000000   0.000000  100.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the best architecture, how accurately can we predict DNAtype?\n",
    "DNAtype_best = NeuralNetworkClassifier(Xtrain_DNAtype.shape[1], [100], len(np.unique(Ttrain_DNAtype)), activation_function='relu')\n",
    "DNAtype_best.train(Xtrain_DNAtype, Ttrain_DNAtype, 500, 0.01, method='adam', verbose=False)\n",
    "DNAtype_best_classes, DNAtype_best_probs = DNAtype_best.use(Xtest_DNAtype)\n",
    "DNAtype_best_cm = confusion_matrix(DNAtype_best_classes, Ttest_DNAtype)\n",
    "DNAtype_best_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c6bcb73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     9267\n",
      "1     2899\n",
      "2      816\n",
      "4       31\n",
      "12       5\n",
      "3        2\n",
      "9        2\n",
      "5        2\n",
      "11       2\n",
      "6        1\n",
      "7        1\n",
      "Name: DNAtype, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Wait, where are the other values? What's with the error? Double checking the data, there are...\n",
    "print(data['DNAtype'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85a6b0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 6 7 9 11 12]\n",
      "[0 1 2 4 5 9 11 12]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(Ttrain_DNAtype))\n",
    "print(np.unique(Ttest_DNAtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bc8cdc",
   "metadata": {},
   "source": [
    "Turns out there are no DNA samples in the data that are DNAtype '8' (leucoplast) or '10' (proplastid). There also weren't any DNAtype '3' samples in the test data. More questions for the authors of the data.\n",
    "\n",
    "The most misclassified DNAtype was '4' (plastid, 28.57). It was misclassified as '2' (chloroplast) at 42.85% and '0' (genomic) at 28.57%. A plastid is a plant cell organelle (mini cell machinery \"organ\"), and chloroplasts (the sites for photosynthesis) are plastids (https://www.nature.com/scitable/topicpage/the-origin-of-plastids-14125758/). Again, more questions about the labeling scheme for the authors.\n",
    "\n",
    "DNAtype '11' (apicoplast) was classified perfectly (100.0%). An apicoplast is an organelle that lives in parasites, such as the one that causes malaria (https://www.nature.com/scitable/topicpage/the-apicoplast-an-organelle-with-a-green-14231555/).\n",
    "\n",
    "The next most accurately classified DNAtypes were '0' (genomic, 99.73) and '1' (mitochondrial, 99.66). Genomic and mitochondrial samples were the two most common sample types. Genomic means a sample that include the entire species' genome (not limited to certain organs etc.), and mitochondria are the organelles that generate most of the chemical energy for the cell (the true powerhouse of the cell, https://www.genome.gov/genetics-glossary/Mitochondria), and is necessary in all living beings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a24933f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27b0877e8b0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# likelihood trace for DNAtype\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(DNAtype_best.error_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73650f9",
   "metadata": {},
   "source": [
    "Are there any correlations between codons and kingdom or codons and DNAtype?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfd36cff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arc' 'bct' 'inv' 'mam' 'phg' 'plm' 'pln' 'pri' 'rod' 'vrl' 'vrt']\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(data['Kingdom']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8160d4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kingdom</th>\n",
       "      <th>DNAtype</th>\n",
       "      <th>SpeciesID</th>\n",
       "      <th>Ncodons</th>\n",
       "      <th>SpeciesName</th>\n",
       "      <th>UUU</th>\n",
       "      <th>UUC</th>\n",
       "      <th>UUA</th>\n",
       "      <th>UUG</th>\n",
       "      <th>CUU</th>\n",
       "      <th>...</th>\n",
       "      <th>CGG</th>\n",
       "      <th>AGA</th>\n",
       "      <th>AGG</th>\n",
       "      <th>GAU</th>\n",
       "      <th>GAC</th>\n",
       "      <th>GAA</th>\n",
       "      <th>GAG</th>\n",
       "      <th>UAA</th>\n",
       "      <th>UAG</th>\n",
       "      <th>UGA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>100217</td>\n",
       "      <td>1995</td>\n",
       "      <td>Epizootic haematopoietic necrosis virus</td>\n",
       "      <td>0.01654</td>\n",
       "      <td>0.01203</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>0.00351</td>\n",
       "      <td>0.01203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00451</td>\n",
       "      <td>0.01303</td>\n",
       "      <td>0.03559</td>\n",
       "      <td>0.01003</td>\n",
       "      <td>0.04612</td>\n",
       "      <td>0.01203</td>\n",
       "      <td>0.04361</td>\n",
       "      <td>0.00251</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>100220</td>\n",
       "      <td>1474</td>\n",
       "      <td>Bohle iridovirus</td>\n",
       "      <td>0.02714</td>\n",
       "      <td>0.01357</td>\n",
       "      <td>0.00068</td>\n",
       "      <td>0.00678</td>\n",
       "      <td>0.00407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00136</td>\n",
       "      <td>0.01696</td>\n",
       "      <td>0.03596</td>\n",
       "      <td>0.01221</td>\n",
       "      <td>0.04545</td>\n",
       "      <td>0.01560</td>\n",
       "      <td>0.04410</td>\n",
       "      <td>0.00271</td>\n",
       "      <td>0.00068</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>100755</td>\n",
       "      <td>4862</td>\n",
       "      <td>Sweet potato leaf curl virus</td>\n",
       "      <td>0.01974</td>\n",
       "      <td>0.02180</td>\n",
       "      <td>0.01357</td>\n",
       "      <td>0.01543</td>\n",
       "      <td>0.00782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00596</td>\n",
       "      <td>0.01974</td>\n",
       "      <td>0.02489</td>\n",
       "      <td>0.03126</td>\n",
       "      <td>0.02036</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.02468</td>\n",
       "      <td>0.00391</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>100880</td>\n",
       "      <td>1915</td>\n",
       "      <td>Northern cereal mosaic virus</td>\n",
       "      <td>0.01775</td>\n",
       "      <td>0.02245</td>\n",
       "      <td>0.01619</td>\n",
       "      <td>0.00992</td>\n",
       "      <td>0.01567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00366</td>\n",
       "      <td>0.01410</td>\n",
       "      <td>0.01671</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.01932</td>\n",
       "      <td>0.03029</td>\n",
       "      <td>0.03446</td>\n",
       "      <td>0.00261</td>\n",
       "      <td>0.00157</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>100887</td>\n",
       "      <td>22831</td>\n",
       "      <td>Soil-borne cereal mosaic virus</td>\n",
       "      <td>0.02816</td>\n",
       "      <td>0.01371</td>\n",
       "      <td>0.00767</td>\n",
       "      <td>0.03679</td>\n",
       "      <td>0.01380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00604</td>\n",
       "      <td>0.01494</td>\n",
       "      <td>0.01734</td>\n",
       "      <td>0.04148</td>\n",
       "      <td>0.02483</td>\n",
       "      <td>0.03359</td>\n",
       "      <td>0.03679</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.00131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13023</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9601</td>\n",
       "      <td>1097</td>\n",
       "      <td>Pongo pygmaeus abelii</td>\n",
       "      <td>0.02552</td>\n",
       "      <td>0.03555</td>\n",
       "      <td>0.00547</td>\n",
       "      <td>0.01367</td>\n",
       "      <td>0.01276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00820</td>\n",
       "      <td>0.01367</td>\n",
       "      <td>0.01094</td>\n",
       "      <td>0.01367</td>\n",
       "      <td>0.02279</td>\n",
       "      <td>0.02005</td>\n",
       "      <td>0.04102</td>\n",
       "      <td>0.00091</td>\n",
       "      <td>0.00091</td>\n",
       "      <td>0.00638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13024</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9601</td>\n",
       "      <td>2067</td>\n",
       "      <td>mitochondrion Pongo pygmaeus abelii</td>\n",
       "      <td>0.01258</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.01984</td>\n",
       "      <td>0.00629</td>\n",
       "      <td>0.01451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00145</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00048</td>\n",
       "      <td>0.00194</td>\n",
       "      <td>0.01306</td>\n",
       "      <td>0.01838</td>\n",
       "      <td>0.00677</td>\n",
       "      <td>0.00242</td>\n",
       "      <td>0.00097</td>\n",
       "      <td>0.01887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13025</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9602</td>\n",
       "      <td>1686</td>\n",
       "      <td>mitochondrion Pongo pygmaeus pygmaeus</td>\n",
       "      <td>0.01423</td>\n",
       "      <td>0.03321</td>\n",
       "      <td>0.01661</td>\n",
       "      <td>0.00356</td>\n",
       "      <td>0.01127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00178</td>\n",
       "      <td>0.01661</td>\n",
       "      <td>0.02788</td>\n",
       "      <td>0.00297</td>\n",
       "      <td>0.00356</td>\n",
       "      <td>0.00119</td>\n",
       "      <td>0.02017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13026</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9606</td>\n",
       "      <td>40662582</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>0.01757</td>\n",
       "      <td>0.02028</td>\n",
       "      <td>0.00767</td>\n",
       "      <td>0.01293</td>\n",
       "      <td>0.01319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01142</td>\n",
       "      <td>0.01217</td>\n",
       "      <td>0.01196</td>\n",
       "      <td>0.02178</td>\n",
       "      <td>0.02510</td>\n",
       "      <td>0.02896</td>\n",
       "      <td>0.03959</td>\n",
       "      <td>0.00099</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>0.00156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13027</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9606</td>\n",
       "      <td>8998998</td>\n",
       "      <td>mitochondrion Homo sapiens</td>\n",
       "      <td>0.01778</td>\n",
       "      <td>0.03724</td>\n",
       "      <td>0.01732</td>\n",
       "      <td>0.00600</td>\n",
       "      <td>0.01689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00083</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.00451</td>\n",
       "      <td>0.01402</td>\n",
       "      <td>0.01651</td>\n",
       "      <td>0.00783</td>\n",
       "      <td>0.00156</td>\n",
       "      <td>0.00114</td>\n",
       "      <td>0.02161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13028 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Kingdom  DNAtype  SpeciesID   Ncodons  \\\n",
       "0            9        0     100217      1995   \n",
       "1            9        0     100220      1474   \n",
       "2            9        0     100755      4862   \n",
       "3            9        0     100880      1915   \n",
       "4            9        0     100887     22831   \n",
       "...        ...      ...        ...       ...   \n",
       "13023        7        0       9601      1097   \n",
       "13024        7        1       9601      2067   \n",
       "13025        7        1       9602      1686   \n",
       "13026        7        0       9606  40662582   \n",
       "13027        7        1       9606   8998998   \n",
       "\n",
       "                                   SpeciesName      UUU      UUC      UUA  \\\n",
       "0      Epizootic haematopoietic necrosis virus  0.01654  0.01203  0.00050   \n",
       "1                             Bohle iridovirus  0.02714  0.01357  0.00068   \n",
       "2                 Sweet potato leaf curl virus  0.01974  0.02180  0.01357   \n",
       "3                 Northern cereal mosaic virus  0.01775  0.02245  0.01619   \n",
       "4               Soil-borne cereal mosaic virus  0.02816  0.01371  0.00767   \n",
       "...                                        ...      ...      ...      ...   \n",
       "13023                    Pongo pygmaeus abelii  0.02552  0.03555  0.00547   \n",
       "13024      mitochondrion Pongo pygmaeus abelii  0.01258  0.03193  0.01984   \n",
       "13025    mitochondrion Pongo pygmaeus pygmaeus  0.01423  0.03321  0.01661   \n",
       "13026                             Homo sapiens  0.01757  0.02028  0.00767   \n",
       "13027               mitochondrion Homo sapiens  0.01778  0.03724  0.01732   \n",
       "\n",
       "           UUG      CUU  ...      CGG      AGA      AGG      GAU      GAC  \\\n",
       "0      0.00351  0.01203  ...  0.00451  0.01303  0.03559  0.01003  0.04612   \n",
       "1      0.00678  0.00407  ...  0.00136  0.01696  0.03596  0.01221  0.04545   \n",
       "2      0.01543  0.00782  ...  0.00596  0.01974  0.02489  0.03126  0.02036   \n",
       "3      0.00992  0.01567  ...  0.00366  0.01410  0.01671  0.03760  0.01932   \n",
       "4      0.03679  0.01380  ...  0.00604  0.01494  0.01734  0.04148  0.02483   \n",
       "...        ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "13023  0.01367  0.01276  ...  0.00820  0.01367  0.01094  0.01367  0.02279   \n",
       "13024  0.00629  0.01451  ...  0.00145  0.00000  0.00048  0.00194  0.01306   \n",
       "13025  0.00356  0.01127  ...  0.00000  0.00000  0.00000  0.00178  0.01661   \n",
       "13026  0.01293  0.01319  ...  0.01142  0.01217  0.01196  0.02178  0.02510   \n",
       "13027  0.00600  0.01689  ...  0.00083  0.00041  0.00041  0.00451  0.01402   \n",
       "\n",
       "           GAA      GAG      UAA      UAG      UGA  \n",
       "0      0.01203  0.04361  0.00251  0.00050  0.00000  \n",
       "1      0.01560  0.04410  0.00271  0.00068  0.00000  \n",
       "2      0.02242  0.02468  0.00391  0.00000  0.00144  \n",
       "3      0.03029  0.03446  0.00261  0.00157  0.00000  \n",
       "4      0.03359  0.03679  0.00000  0.00044  0.00131  \n",
       "...        ...      ...      ...      ...      ...  \n",
       "13023  0.02005  0.04102  0.00091  0.00091  0.00638  \n",
       "13024  0.01838  0.00677  0.00242  0.00097  0.01887  \n",
       "13025  0.02788  0.00297  0.00356  0.00119  0.02017  \n",
       "13026  0.02896  0.03959  0.00099  0.00079  0.00156  \n",
       "13027  0.01651  0.00783  0.00156  0.00114  0.02161  \n",
       "\n",
       "[13028 rows x 69 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make everything numbers for some easy correlations that Pandas will do for me\n",
    "data['Kingdom'] = data['Kingdom'].replace(['arc', 'bct', 'inv', 'mam', 'phg', 'plm', 'pln', 'pri', 'rod', 'vrl', 'vrt'],\n",
    "                                          [0,1,2,3,4,5,6,7,8,9,10])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dce0187b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kingdom</th>\n",
       "      <th>DNAtype</th>\n",
       "      <th>SpeciesID</th>\n",
       "      <th>Ncodons</th>\n",
       "      <th>UUU</th>\n",
       "      <th>UUC</th>\n",
       "      <th>UUA</th>\n",
       "      <th>UUG</th>\n",
       "      <th>CUU</th>\n",
       "      <th>CUC</th>\n",
       "      <th>...</th>\n",
       "      <th>CGG</th>\n",
       "      <th>AGA</th>\n",
       "      <th>AGG</th>\n",
       "      <th>GAU</th>\n",
       "      <th>GAC</th>\n",
       "      <th>GAA</th>\n",
       "      <th>GAG</th>\n",
       "      <th>UAA</th>\n",
       "      <th>UAG</th>\n",
       "      <th>UGA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kingdom</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169479</td>\n",
       "      <td>0.058942</td>\n",
       "      <td>-0.075663</td>\n",
       "      <td>0.007493</td>\n",
       "      <td>0.167831</td>\n",
       "      <td>-0.029749</td>\n",
       "      <td>-0.070904</td>\n",
       "      <td>0.297460</td>\n",
       "      <td>0.228316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265591</td>\n",
       "      <td>0.064279</td>\n",
       "      <td>0.185943</td>\n",
       "      <td>-0.234331</td>\n",
       "      <td>-0.238411</td>\n",
       "      <td>-0.263376</td>\n",
       "      <td>-0.194454</td>\n",
       "      <td>0.052493</td>\n",
       "      <td>0.019269</td>\n",
       "      <td>0.261049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DNAtype</th>\n",
       "      <td>0.169479</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020671</td>\n",
       "      <td>-0.053869</td>\n",
       "      <td>0.456915</td>\n",
       "      <td>0.192253</td>\n",
       "      <td>0.460169</td>\n",
       "      <td>-0.039323</td>\n",
       "      <td>0.379370</td>\n",
       "      <td>0.067454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.218555</td>\n",
       "      <td>-0.085856</td>\n",
       "      <td>-0.324560</td>\n",
       "      <td>-0.273859</td>\n",
       "      <td>-0.459336</td>\n",
       "      <td>-0.100732</td>\n",
       "      <td>-0.497574</td>\n",
       "      <td>0.127702</td>\n",
       "      <td>-0.029417</td>\n",
       "      <td>0.458569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpeciesID</th>\n",
       "      <td>0.058942</td>\n",
       "      <td>-0.020671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051598</td>\n",
       "      <td>0.020018</td>\n",
       "      <td>-0.016733</td>\n",
       "      <td>0.025688</td>\n",
       "      <td>-0.047719</td>\n",
       "      <td>0.055717</td>\n",
       "      <td>0.022057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011089</td>\n",
       "      <td>-0.026525</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>-0.005584</td>\n",
       "      <td>-0.028789</td>\n",
       "      <td>-0.014054</td>\n",
       "      <td>-0.079133</td>\n",
       "      <td>0.047511</td>\n",
       "      <td>-0.012816</td>\n",
       "      <td>0.050160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ncodons</th>\n",
       "      <td>-0.075663</td>\n",
       "      <td>-0.053869</td>\n",
       "      <td>0.051598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.035154</td>\n",
       "      <td>-0.028123</td>\n",
       "      <td>-0.033710</td>\n",
       "      <td>0.009492</td>\n",
       "      <td>-0.040635</td>\n",
       "      <td>-0.001745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068370</td>\n",
       "      <td>-0.010998</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.024785</td>\n",
       "      <td>0.034607</td>\n",
       "      <td>0.028564</td>\n",
       "      <td>0.053023</td>\n",
       "      <td>-0.026612</td>\n",
       "      <td>0.003677</td>\n",
       "      <td>-0.047958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UUU</th>\n",
       "      <td>0.007493</td>\n",
       "      <td>0.456915</td>\n",
       "      <td>0.020018</td>\n",
       "      <td>-0.035154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.354083</td>\n",
       "      <td>0.761390</td>\n",
       "      <td>0.337760</td>\n",
       "      <td>0.312967</td>\n",
       "      <td>-0.433250</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.343606</td>\n",
       "      <td>0.303605</td>\n",
       "      <td>-0.104975</td>\n",
       "      <td>0.163682</td>\n",
       "      <td>-0.598977</td>\n",
       "      <td>0.154091</td>\n",
       "      <td>-0.452491</td>\n",
       "      <td>0.161922</td>\n",
       "      <td>0.008285</td>\n",
       "      <td>0.154572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAA</th>\n",
       "      <td>-0.263376</td>\n",
       "      <td>-0.100732</td>\n",
       "      <td>-0.014054</td>\n",
       "      <td>0.028564</td>\n",
       "      <td>0.154091</td>\n",
       "      <td>-0.464520</td>\n",
       "      <td>0.188351</td>\n",
       "      <td>0.315404</td>\n",
       "      <td>-0.028047</td>\n",
       "      <td>-0.532899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228033</td>\n",
       "      <td>0.476702</td>\n",
       "      <td>0.046328</td>\n",
       "      <td>0.684480</td>\n",
       "      <td>-0.218420</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.085162</td>\n",
       "      <td>0.077879</td>\n",
       "      <td>-0.019792</td>\n",
       "      <td>-0.402001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAG</th>\n",
       "      <td>-0.194454</td>\n",
       "      <td>-0.497574</td>\n",
       "      <td>-0.079133</td>\n",
       "      <td>0.053023</td>\n",
       "      <td>-0.452491</td>\n",
       "      <td>-0.079002</td>\n",
       "      <td>-0.577687</td>\n",
       "      <td>0.115323</td>\n",
       "      <td>-0.430695</td>\n",
       "      <td>0.013356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524379</td>\n",
       "      <td>0.057005</td>\n",
       "      <td>0.477482</td>\n",
       "      <td>0.120200</td>\n",
       "      <td>0.673022</td>\n",
       "      <td>-0.085162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.289657</td>\n",
       "      <td>0.004036</td>\n",
       "      <td>-0.582578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UAA</th>\n",
       "      <td>0.052493</td>\n",
       "      <td>0.127702</td>\n",
       "      <td>0.047511</td>\n",
       "      <td>-0.026612</td>\n",
       "      <td>0.161922</td>\n",
       "      <td>-0.014834</td>\n",
       "      <td>0.263113</td>\n",
       "      <td>-0.131225</td>\n",
       "      <td>0.168436</td>\n",
       "      <td>0.014527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251605</td>\n",
       "      <td>0.020103</td>\n",
       "      <td>-0.157387</td>\n",
       "      <td>-0.067417</td>\n",
       "      <td>-0.292131</td>\n",
       "      <td>0.077879</td>\n",
       "      <td>-0.289657</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136473</td>\n",
       "      <td>0.276998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UAG</th>\n",
       "      <td>0.019269</td>\n",
       "      <td>-0.029417</td>\n",
       "      <td>-0.012816</td>\n",
       "      <td>0.003677</td>\n",
       "      <td>0.008285</td>\n",
       "      <td>-0.046411</td>\n",
       "      <td>0.009585</td>\n",
       "      <td>0.053591</td>\n",
       "      <td>0.010321</td>\n",
       "      <td>-0.009272</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001661</td>\n",
       "      <td>0.050214</td>\n",
       "      <td>0.085773</td>\n",
       "      <td>-0.010157</td>\n",
       "      <td>-0.053811</td>\n",
       "      <td>-0.019792</td>\n",
       "      <td>0.004036</td>\n",
       "      <td>0.136473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UGA</th>\n",
       "      <td>0.261049</td>\n",
       "      <td>0.458569</td>\n",
       "      <td>0.050160</td>\n",
       "      <td>-0.047958</td>\n",
       "      <td>0.154572</td>\n",
       "      <td>0.441258</td>\n",
       "      <td>0.331493</td>\n",
       "      <td>-0.468167</td>\n",
       "      <td>0.422518</td>\n",
       "      <td>0.469257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.282878</td>\n",
       "      <td>-0.424566</td>\n",
       "      <td>-0.451961</td>\n",
       "      <td>-0.631297</td>\n",
       "      <td>-0.360237</td>\n",
       "      <td>-0.402001</td>\n",
       "      <td>-0.582578</td>\n",
       "      <td>0.276998</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Kingdom   DNAtype  SpeciesID   Ncodons       UUU       UUC  \\\n",
       "Kingdom    1.000000  0.169479   0.058942 -0.075663  0.007493  0.167831   \n",
       "DNAtype    0.169479  1.000000  -0.020671 -0.053869  0.456915  0.192253   \n",
       "SpeciesID  0.058942 -0.020671   1.000000  0.051598  0.020018 -0.016733   \n",
       "Ncodons   -0.075663 -0.053869   0.051598  1.000000 -0.035154 -0.028123   \n",
       "UUU        0.007493  0.456915   0.020018 -0.035154  1.000000 -0.354083   \n",
       "...             ...       ...        ...       ...       ...       ...   \n",
       "GAA       -0.263376 -0.100732  -0.014054  0.028564  0.154091 -0.464520   \n",
       "GAG       -0.194454 -0.497574  -0.079133  0.053023 -0.452491 -0.079002   \n",
       "UAA        0.052493  0.127702   0.047511 -0.026612  0.161922 -0.014834   \n",
       "UAG        0.019269 -0.029417  -0.012816  0.003677  0.008285 -0.046411   \n",
       "UGA        0.261049  0.458569   0.050160 -0.047958  0.154572  0.441258   \n",
       "\n",
       "                UUA       UUG       CUU       CUC  ...       CGG       AGA  \\\n",
       "Kingdom   -0.029749 -0.070904  0.297460  0.228316  ... -0.265591  0.064279   \n",
       "DNAtype    0.460169 -0.039323  0.379370  0.067454  ... -0.218555 -0.085856   \n",
       "SpeciesID  0.025688 -0.047719  0.055717  0.022057  ...  0.011089 -0.026525   \n",
       "Ncodons   -0.033710  0.009492 -0.040635 -0.001745  ...  0.068370 -0.010998   \n",
       "UUU        0.761390  0.337760  0.312967 -0.433250  ... -0.343606  0.303605   \n",
       "...             ...       ...       ...       ...  ...       ...       ...   \n",
       "GAA        0.188351  0.315404 -0.028047 -0.532899  ... -0.228033  0.476702   \n",
       "GAG       -0.577687  0.115323 -0.430695  0.013356  ...  0.524379  0.057005   \n",
       "UAA        0.263113 -0.131225  0.168436  0.014527  ... -0.251605  0.020103   \n",
       "UAG        0.009585  0.053591  0.010321 -0.009272  ... -0.001661  0.050214   \n",
       "UGA        0.331493 -0.468167  0.422518  0.469257  ... -0.282878 -0.424566   \n",
       "\n",
       "                AGG       GAU       GAC       GAA       GAG       UAA  \\\n",
       "Kingdom    0.185943 -0.234331 -0.238411 -0.263376 -0.194454  0.052493   \n",
       "DNAtype   -0.324560 -0.273859 -0.459336 -0.100732 -0.497574  0.127702   \n",
       "SpeciesID -0.000409 -0.005584 -0.028789 -0.014054 -0.079133  0.047511   \n",
       "Ncodons    0.001501  0.024785  0.034607  0.028564  0.053023 -0.026612   \n",
       "UUU       -0.104975  0.163682 -0.598977  0.154091 -0.452491  0.161922   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "GAA        0.046328  0.684480 -0.218420  1.000000 -0.085162  0.077879   \n",
       "GAG        0.477482  0.120200  0.673022 -0.085162  1.000000 -0.289657   \n",
       "UAA       -0.157387 -0.067417 -0.292131  0.077879 -0.289657  1.000000   \n",
       "UAG        0.085773 -0.010157 -0.053811 -0.019792  0.004036  0.136473   \n",
       "UGA       -0.451961 -0.631297 -0.360237 -0.402001 -0.582578  0.276998   \n",
       "\n",
       "                UAG       UGA  \n",
       "Kingdom    0.019269  0.261049  \n",
       "DNAtype   -0.029417  0.458569  \n",
       "SpeciesID -0.012816  0.050160  \n",
       "Ncodons    0.003677 -0.047958  \n",
       "UUU        0.008285  0.154572  \n",
       "...             ...       ...  \n",
       "GAA       -0.019792 -0.402001  \n",
       "GAG        0.004036 -0.582578  \n",
       "UAA        0.136473  0.276998  \n",
       "UAG        1.000000  0.007049  \n",
       "UGA        0.007049  1.000000  \n",
       "\n",
       "[68 rows x 68 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_corr = data.corr()\n",
    "data_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "458e06f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['UUU'],\n",
       "       ['UUC'],\n",
       "       ['UUA'],\n",
       "       ['UUG'],\n",
       "       ['CUU'],\n",
       "       ['CUC'],\n",
       "       ['CUA'],\n",
       "       ['CUG'],\n",
       "       ['AUU'],\n",
       "       ['AUC'],\n",
       "       ['AUA'],\n",
       "       ['AUG'],\n",
       "       ['GUU'],\n",
       "       ['GUC'],\n",
       "       ['GUA'],\n",
       "       ['GUG'],\n",
       "       ['GCU'],\n",
       "       ['GCC'],\n",
       "       ['GCA'],\n",
       "       ['GCG'],\n",
       "       ['CCU'],\n",
       "       ['CCC'],\n",
       "       ['CCA'],\n",
       "       ['CCG'],\n",
       "       ['UGG'],\n",
       "       ['GGU'],\n",
       "       ['GGC'],\n",
       "       ['GGA'],\n",
       "       ['GGG'],\n",
       "       ['UCU'],\n",
       "       ['UCC'],\n",
       "       ['UCA'],\n",
       "       ['UCG'],\n",
       "       ['AGU'],\n",
       "       ['AGC'],\n",
       "       ['ACU'],\n",
       "       ['ACC'],\n",
       "       ['ACA'],\n",
       "       ['ACG'],\n",
       "       ['UAU'],\n",
       "       ['UAC'],\n",
       "       ['CAA'],\n",
       "       ['CAG'],\n",
       "       ['AAU'],\n",
       "       ['AAC'],\n",
       "       ['UGU'],\n",
       "       ['UGC'],\n",
       "       ['CAU'],\n",
       "       ['CAC'],\n",
       "       ['AAA'],\n",
       "       ['AAG'],\n",
       "       ['CGU'],\n",
       "       ['CGC'],\n",
       "       ['CGA'],\n",
       "       ['CGG'],\n",
       "       ['AGA'],\n",
       "       ['AGG'],\n",
       "       ['GAU'],\n",
       "       ['GAC'],\n",
       "       ['GAA'],\n",
       "       ['GAG'],\n",
       "       ['UAA'],\n",
       "       ['UAG'],\n",
       "       ['UGA']], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# that's a lot to look at...we just want codons -> kingdom and codons -> DNAtype\n",
    "codon_labels = data.columns[5:].to_numpy().reshape((-1,1))\n",
    "codon_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ab3e129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['UUU', 0.0074931456132936594],\n",
       "       ['UUC', 0.16783141678300564],\n",
       "       ['UUA', -0.029749275587980815],\n",
       "       ['UUG', -0.07090373018036514],\n",
       "       ['CUU', 0.29746018466104157],\n",
       "       ['CUC', 0.22831552451801176],\n",
       "       ['CUA', 0.35482234736113355],\n",
       "       ['CUG', -0.22721768568268833],\n",
       "       ['AUU', 0.004358962827683957],\n",
       "       ['AUC', 0.0615276986094823],\n",
       "       ['AUA', 0.17960941184701845],\n",
       "       ['AUG', -0.10614724220713524],\n",
       "       ['GUU', -0.07370733326788549],\n",
       "       ['GUC', -0.178478522256799],\n",
       "       ['GUA', 0.04872700945992732],\n",
       "       ['GUG', -0.1802572259210716],\n",
       "       ['GCU', 0.003447417008824879],\n",
       "       ['GCC', -0.06686636772130382],\n",
       "       ['GCA', 0.1425912356584615],\n",
       "       ['GCG', -0.41927299963068965],\n",
       "       ['CCU', 0.25446539147395275],\n",
       "       ['CCC', 0.28389982130390196],\n",
       "       ['CCA', 0.4097450236236333],\n",
       "       ['CCG', -0.3791905941740217],\n",
       "       ['UGG', -0.11034246818218699],\n",
       "       ['GGU', -0.25969134138750916],\n",
       "       ['GGC', -0.3068446675613557],\n",
       "       ['GGA', 0.1214714206952555],\n",
       "       ['GGG', 0.027358194660532815],\n",
       "       ['UCU', 0.13325004778428742],\n",
       "       ['UCC', 0.30804178870772586],\n",
       "       ['UCA', 0.312441994573521],\n",
       "       ['UCG', -0.2790017824898473],\n",
       "       ['AGU', -0.036559782452963686],\n",
       "       ['AGC', -0.04508273710358313],\n",
       "       ['ACU', 0.2622091469006229],\n",
       "       ['ACC', 0.16806737704046001],\n",
       "       ['ACA', 0.37927072501627923],\n",
       "       ['ACG', -0.28886399573750987],\n",
       "       ['UAU', -0.06906833122716731],\n",
       "       ['UAC', 0.09162367885438812],\n",
       "       ['CAA', 0.14742835605630777],\n",
       "       ['CAG', -0.15654431517176992],\n",
       "       ['AAU', -0.06135000774768277],\n",
       "       ['AAC', 0.15711361347504235],\n",
       "       ['UGU', 0.2060989959383011],\n",
       "       ['UGC', 0.14248914024745282],\n",
       "       ['CAU', 0.003008232470629562],\n",
       "       ['CAC', 0.18270442407822537],\n",
       "       ['AAA', -0.09777452848277733],\n",
       "       ['AAG', -0.1289198159913954],\n",
       "       ['CGU', -0.28289082488372325],\n",
       "       ['CGC', -0.3668026485888255],\n",
       "       ['CGA', 0.18507568094927596],\n",
       "       ['CGG', -0.2655907655816539],\n",
       "       ['AGA', 0.06427919295304814],\n",
       "       ['AGG', 0.1859426887737349],\n",
       "       ['GAU', -0.23433082853887455],\n",
       "       ['GAC', -0.238411226901013],\n",
       "       ['GAA', -0.263376197962943],\n",
       "       ['GAG', -0.194453515686013],\n",
       "       ['UAA', 0.05249329701787304],\n",
       "       ['UAG', 0.01926856358259548],\n",
       "       ['UGA', 0.2610486552999621]], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pair codon labels with correlations\n",
    "data_corr_arr = data_corr.to_numpy()\n",
    "kingdom_pred = data_corr_arr[4:,0].reshape((-1,1)) # correlations of codons -> kingdom only\n",
    "kingdom_pred_labeled = np.hstack((codon_labels, kingdom_pred))\n",
    "kingdom_pred_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dad43d7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['GCG', -0.41927299963068965],\n",
       "       ['CCG', -0.3791905941740217],\n",
       "       ['CGC', -0.3668026485888255],\n",
       "       ['GGC', -0.3068446675613557],\n",
       "       ['ACG', -0.28886399573750987],\n",
       "       ['CGU', -0.28289082488372325],\n",
       "       ['UCG', -0.2790017824898473],\n",
       "       ['CGG', -0.2655907655816539],\n",
       "       ['GAA', -0.263376197962943],\n",
       "       ['GGU', -0.25969134138750916],\n",
       "       ['GAC', -0.238411226901013],\n",
       "       ['GAU', -0.23433082853887455],\n",
       "       ['CUG', -0.22721768568268833],\n",
       "       ['GAG', -0.194453515686013],\n",
       "       ['GUG', -0.1802572259210716],\n",
       "       ['GUC', -0.178478522256799],\n",
       "       ['CAG', -0.15654431517176992],\n",
       "       ['AAG', -0.1289198159913954],\n",
       "       ['UGG', -0.11034246818218699],\n",
       "       ['AUG', -0.10614724220713524],\n",
       "       ['AAA', -0.09777452848277733],\n",
       "       ['GUU', -0.07370733326788549],\n",
       "       ['UUG', -0.07090373018036514],\n",
       "       ['UAU', -0.06906833122716731],\n",
       "       ['GCC', -0.06686636772130382],\n",
       "       ['AAU', -0.06135000774768277],\n",
       "       ['AGC', -0.04508273710358313],\n",
       "       ['AGU', -0.036559782452963686],\n",
       "       ['UUA', -0.029749275587980815],\n",
       "       ['CAU', 0.003008232470629562],\n",
       "       ['GCU', 0.003447417008824879],\n",
       "       ['AUU', 0.004358962827683957],\n",
       "       ['UUU', 0.0074931456132936594],\n",
       "       ['UAG', 0.01926856358259548],\n",
       "       ['GGG', 0.027358194660532815],\n",
       "       ['GUA', 0.04872700945992732],\n",
       "       ['UAA', 0.05249329701787304],\n",
       "       ['AUC', 0.0615276986094823],\n",
       "       ['AGA', 0.06427919295304814],\n",
       "       ['UAC', 0.09162367885438812],\n",
       "       ['GGA', 0.1214714206952555],\n",
       "       ['UCU', 0.13325004778428742],\n",
       "       ['UGC', 0.14248914024745282],\n",
       "       ['GCA', 0.1425912356584615],\n",
       "       ['CAA', 0.14742835605630777],\n",
       "       ['AAC', 0.15711361347504235],\n",
       "       ['UUC', 0.16783141678300564],\n",
       "       ['ACC', 0.16806737704046001],\n",
       "       ['AUA', 0.17960941184701845],\n",
       "       ['CAC', 0.18270442407822537],\n",
       "       ['CGA', 0.18507568094927596],\n",
       "       ['AGG', 0.1859426887737349],\n",
       "       ['UGU', 0.2060989959383011],\n",
       "       ['CUC', 0.22831552451801176],\n",
       "       ['CCU', 0.25446539147395275],\n",
       "       ['UGA', 0.2610486552999621],\n",
       "       ['ACU', 0.2622091469006229],\n",
       "       ['CCC', 0.28389982130390196],\n",
       "       ['CUU', 0.29746018466104157],\n",
       "       ['UCC', 0.30804178870772586],\n",
       "       ['UCA', 0.312441994573521],\n",
       "       ['CUA', 0.35482234736113355],\n",
       "       ['ACA', 0.37927072501627923],\n",
       "       ['CCA', 0.4097450236236333]], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by correlation to see extremes\n",
    "kingdom_pred_labeled_sorted = kingdom_pred_labeled[np.argsort(kingdom_pred_labeled[:,1])]\n",
    "kingdom_pred_labeled_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cea5cbd",
   "metadata": {},
   "source": [
    "According to the Boston University School of Public Health, the correlation coefficient is a measure of the closeness of association of data points: positive values show a positive correlation, negative values show a negative correlation, and values closer to zero show that a correlation is weak (or zero) (https://sphweb.bumc.bu.edu/otlt/MPH-Modules/PH717-QuantCore/PH717-Module9-Correlation-Regression/PH717-Module9-Correlation-Regression4.html). We will focus on values that are less than -0.3 or greater than 0.3 for this evaluation.\n",
    "\n",
    "#### Kingdoms:\n",
    "\n",
    "GCG (alanine, -0.419), CCG (proline, -0.379), CGC (arginine, -0.367), and GGC (glycine, -0.307) have stronger negative correlation coefficients.\n",
    "\n",
    "CCA (proline, 0.409), ACA (threonine, 0.379), CUA (leucine, 0.355), UCA (serine, 0.312), and UCC (serine, 0.308) have stronger positive correlation coefficients.\n",
    "\n",
    "It is interesting to see that different codons that code for proline (CCG and CCA) have opposite correlations (negative and positive, respectively). This suggests that certain kingdoms will favor one proline codon over the other. The other proline codons (CCU, 0.254 and CCC, 0.284) also have positive correlation coefficients.\n",
    "\n",
    "It is also interesting to see that two serine codons (UCA, UCC) have similar positive correlation coefficients. The other serine codons have negative coefficient correlations (UCG, -0.279), (AGU, -0.037), and (AGC, -0.045), except for (UCU, 0.133).\n",
    "\n",
    "Other codons of interest are AUG (methionine/START, -0.106), UAA (STOP, 0.0525), UAG (STOP, 0.0192), and UGA (STOP, 0.261). It makes sense that these don't have strong correlations to determining a species' kingdom. Every being needs these codons, so they will be abundant regardless of kingdom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ac992e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['UUU', 0.4569145674162792],\n",
       "       ['UUC', 0.19225272744747104],\n",
       "       ['UUA', 0.46016901592528225],\n",
       "       ['UUG', -0.03932270248887432],\n",
       "       ['CUU', 0.3793703409224325],\n",
       "       ['CUC', 0.06745361074864516],\n",
       "       ['CUA', 0.45911356148792726],\n",
       "       ['CUG', -0.31450643652714627],\n",
       "       ['AUU', 0.4594599581002439],\n",
       "       ['AUC', 0.13985445705014313],\n",
       "       ['AUA', 0.4505831709370647],\n",
       "       ['AUG', -0.37083993710486896],\n",
       "       ['GUU', -0.07587754595485852],\n",
       "       ['GUC', -0.32661469984833613],\n",
       "       ['GUA', 0.38878538164471177],\n",
       "       ['GUG', -0.444590055654474],\n",
       "       ['GCU', -0.054742428076469604],\n",
       "       ['GCC', -0.12038931343212259],\n",
       "       ['GCA', 0.03843082410819814],\n",
       "       ['GCG', -0.32189341043005903],\n",
       "       ['CCU', 0.03996064206926092],\n",
       "       ['CCC', 0.030958074771004686],\n",
       "       ['CCA', 0.1623294871823376],\n",
       "       ['CCG', -0.3271469022437793],\n",
       "       ['UGG', -0.2539214445059419],\n",
       "       ['GGU', -0.15021268399718551],\n",
       "       ['GGC', -0.28734737042789743],\n",
       "       ['GGA', 0.1627060404973048],\n",
       "       ['GGG', -0.11874357504266429],\n",
       "       ['UCU', 0.31825423364320055],\n",
       "       ['UCC', 0.11752805340142886],\n",
       "       ['UCA', 0.3691833934325319],\n",
       "       ['UCG', -0.2676448452215862],\n",
       "       ['AGU', -0.05480372590153667],\n",
       "       ['AGC', -0.3785542360702759],\n",
       "       ['ACU', 0.12509957697437993],\n",
       "       ['ACC', -0.010447358388514485],\n",
       "       ['ACA', 0.20662542291581937],\n",
       "       ['ACG', -0.3860045380686385],\n",
       "       ['UAU', 0.3088113630776947],\n",
       "       ['UAC', -0.19187371880608467],\n",
       "       ['CAA', 0.13553657014015735],\n",
       "       ['CAG', -0.4971461519775949],\n",
       "       ['AAU', 0.09771296531792359],\n",
       "       ['AAC', -0.18468420729921897],\n",
       "       ['UGU', -0.09206750431500058],\n",
       "       ['UGC', -0.31015640697744806],\n",
       "       ['CAU', 0.22543381003621202],\n",
       "       ['CAC', -0.01963210478029033],\n",
       "       ['AAA', 0.10058247476768876],\n",
       "       ['AAG', -0.4947523334190914],\n",
       "       ['CGU', -0.0773534244257816],\n",
       "       ['CGC', -0.29414656294897384],\n",
       "       ['CGA', 0.48725329951294294],\n",
       "       ['CGG', -0.21855511039370717],\n",
       "       ['AGA', -0.08585622939499013],\n",
       "       ['AGG', -0.32455998583680873],\n",
       "       ['GAU', -0.27385919052907853],\n",
       "       ['GAC', -0.4593359383425588],\n",
       "       ['GAA', -0.10073184528288262],\n",
       "       ['GAG', -0.4975740566206373],\n",
       "       ['UAA', 0.12770201698762476],\n",
       "       ['UAG', -0.029417276599903095],\n",
       "       ['UGA', 0.45856908288055154]], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNAtype_pred = data_corr_arr[4:,1].reshape((-1,1))\n",
    "DNAtype_pred_labeled = np.hstack((codon_labels, DNAtype_pred)) # correlations of codons -> DNAtype only\n",
    "DNAtype_pred_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "233f381e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['GAG', -0.4975740566206373],\n",
       "       ['CAG', -0.4971461519775949],\n",
       "       ['AAG', -0.4947523334190914],\n",
       "       ['GAC', -0.4593359383425588],\n",
       "       ['GUG', -0.444590055654474],\n",
       "       ['ACG', -0.3860045380686385],\n",
       "       ['AGC', -0.3785542360702759],\n",
       "       ['AUG', -0.37083993710486896],\n",
       "       ['CCG', -0.3271469022437793],\n",
       "       ['GUC', -0.32661469984833613],\n",
       "       ['AGG', -0.32455998583680873],\n",
       "       ['GCG', -0.32189341043005903],\n",
       "       ['CUG', -0.31450643652714627],\n",
       "       ['UGC', -0.31015640697744806],\n",
       "       ['CGC', -0.29414656294897384],\n",
       "       ['GGC', -0.28734737042789743],\n",
       "       ['GAU', -0.27385919052907853],\n",
       "       ['UCG', -0.2676448452215862],\n",
       "       ['UGG', -0.2539214445059419],\n",
       "       ['CGG', -0.21855511039370717],\n",
       "       ['UAC', -0.19187371880608467],\n",
       "       ['AAC', -0.18468420729921897],\n",
       "       ['GGU', -0.15021268399718551],\n",
       "       ['GCC', -0.12038931343212259],\n",
       "       ['GGG', -0.11874357504266429],\n",
       "       ['GAA', -0.10073184528288262],\n",
       "       ['UGU', -0.09206750431500058],\n",
       "       ['AGA', -0.08585622939499013],\n",
       "       ['CGU', -0.0773534244257816],\n",
       "       ['GUU', -0.07587754595485852],\n",
       "       ['AGU', -0.05480372590153667],\n",
       "       ['GCU', -0.054742428076469604],\n",
       "       ['UUG', -0.03932270248887432],\n",
       "       ['UAG', -0.029417276599903095],\n",
       "       ['CAC', -0.01963210478029033],\n",
       "       ['ACC', -0.010447358388514485],\n",
       "       ['CCC', 0.030958074771004686],\n",
       "       ['GCA', 0.03843082410819814],\n",
       "       ['CCU', 0.03996064206926092],\n",
       "       ['CUC', 0.06745361074864516],\n",
       "       ['AAU', 0.09771296531792359],\n",
       "       ['AAA', 0.10058247476768876],\n",
       "       ['UCC', 0.11752805340142886],\n",
       "       ['ACU', 0.12509957697437993],\n",
       "       ['UAA', 0.12770201698762476],\n",
       "       ['CAA', 0.13553657014015735],\n",
       "       ['AUC', 0.13985445705014313],\n",
       "       ['CCA', 0.1623294871823376],\n",
       "       ['GGA', 0.1627060404973048],\n",
       "       ['UUC', 0.19225272744747104],\n",
       "       ['ACA', 0.20662542291581937],\n",
       "       ['CAU', 0.22543381003621202],\n",
       "       ['UAU', 0.3088113630776947],\n",
       "       ['UCU', 0.31825423364320055],\n",
       "       ['UCA', 0.3691833934325319],\n",
       "       ['CUU', 0.3793703409224325],\n",
       "       ['GUA', 0.38878538164471177],\n",
       "       ['AUA', 0.4505831709370647],\n",
       "       ['UUU', 0.4569145674162792],\n",
       "       ['UGA', 0.45856908288055154],\n",
       "       ['CUA', 0.45911356148792726],\n",
       "       ['AUU', 0.4594599581002439],\n",
       "       ['UUA', 0.46016901592528225],\n",
       "       ['CGA', 0.48725329951294294]], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by correlation to see extremes\n",
    "DNAtype_pred_labeled_sorted = DNAtype_pred_labeled[np.argsort(DNAtype_pred_labeled[:,1])]\n",
    "DNAtype_pred_labeled_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be44151",
   "metadata": {},
   "source": [
    "#### DNAtype:\n",
    "\n",
    "GAG (glutamic acid, -0.498), CAG (glutamine, -0.497), AAG (lysine, -0.495), GAC (aspartic acid, -0.459), GUG (valine, -0.445), ACG (threonine, -0.386), AGC (serine, -0.379), AUG (methionine/START, -0.371), CCG (proline, -0.327), GUC (valine, -0.327), AGG (arginine, -0.325), GCG (alanine, -0.322), CUG (leucine, -0.315), UGC (cysteine, -0.310).\n",
    "\n",
    "CGA (arginine, 0.487), UUA (leucine, 0.460), AUU (isoleucine, 0.459), CUA (leucine, 0.459), UGA (STOP, 0.459), UUU (phenylalanine, 0.457), AUA (isoleucine, 0.451), GUA (valine, 0.389), CUU (leucine, 0.379), UCA (serine, 0.369), UCU (serine, 0.318), UAU (tyrosine, 0.309).\n",
    "\n",
    "It is interesting to see that different codons that code for valine (GUG, GUC and GUA) have opposite correlations (negative and positive, respectively). This suggests that certain DNAtypes will favor GUA valine codons over the other two. The other valine codon (GUU, -0.076) is almost negligible.\n",
    "\n",
    "It is also interesting to see that serine is important again here in DNAtype. AGC, AGU, and UCG had negative correlation coefficients (-0.379, -0.055, and -0.268 respectively). UCA, UCU, and UCC had positive correlation coefficients (0.369, 0.318, and 0.118 respectively).\n",
    "\n",
    "Other codons of interest are UAA (STOP, 0.128) and UAG (STOP, -0.029). It is likely that these are both common stop codons in all DNAtypes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbe081d",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n",
    "Genomic sequencing studies continue to be intense processes that involve a lot of time and power. By utilizing machine learning, organizations can quickly make predictions about new DNA sequences. Identifying previously unknown viral families can help in keeping humanity more suited to treat illness and better prepared for potential pandemics in the future (https://www.pennmedicine.org/news/news-releases/2019/may/how-do-you-find-a-virus-thats-completely-unknown-study-says-look-to-the-genome). The neural network classifier architecture deemed best from these experiments (determined by highest accuracy on validation data) was:\n",
    "\n",
    "|  |Hidden Layers | Epochs | Learning Rate | Activation Function | Optimization | Train | Validate | Test | Time |\n",
    "|---|---|---|---|---|---|---|---|---|---|\n",
    "| kingdom | [100] | 500 | 0.01 | relu | adam | 100.00000 | 92.207294 | 93.358925 | 24.87s |\n",
    "| DNAtype | [100] | 500 | 0.01 | relu | adam | 99.961627 | 99.309021 | 99.078695 | 21.20s |\n",
    "\n",
    "The networks with this architecture achieved 93.36% test data accuracy on predicting kingdoms from codon frequencies and 99.08% test data accuracy on predicting DNAtype from codon frequencies. Further research would be worthwhile by focusing on nucleotide frequencies to determine why certain kingdoms or DNAtypes are more likely to use one codon over another that codes for the same amino acid.\n",
    "\n",
    "Thank you for a wonderful semester! I really enjoyed working on this project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
